{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model results for simulated and natural populations\n",
    "\n",
    "Plots model results for all populations by timepoint including those shown in Figures 2, 3, 5, and 6 and Supplemental Figures S3, S6, and S8.\n",
    "\n",
    "Generates tables of model results for all populations including those in Tables 1 and 2 and Supplemental Table S3.\n",
    "\n",
    "Plots cross-validation approaches shown in Supplemental Figures S1 and S5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define inputs.\n",
    "errors_file = snakemake.input.model_distances\n",
    "coefficients_file = snakemake.input.model_coefficients\n",
    "bootstrap_p_values_file = snakemake.input.bootstrap_p_values\n",
    "\n",
    "# Define outputs.\n",
    "table_for_simulated_model_selection = snakemake.output.table_for_simulated_model_selection\n",
    "source_data_for_simulated_model_coefficients = snakemake.output.source_data_for_simulated_model_coefficients\n",
    "source_data_for_simulated_model_distances = snakemake.output.source_data_for_simulated_model_distances\n",
    "\n",
    "figure_for_simulated_model_controls = snakemake.output.figure_for_simulated_model_controls\n",
    "figure_for_simulated_individual_models = snakemake.output.figure_for_simulated_individual_models\n",
    "figure_for_simulated_composite_models = snakemake.output.figure_for_simulated_composite_models\n",
    "\n",
    "table_for_natural_model_selection = snakemake.output.table_for_natural_model_selection\n",
    "table_for_natural_model_complete_selection = snakemake.output.table_for_natural_model_complete_selection\n",
    "source_data_for_natural_model_coefficients = snakemake.output.source_data_for_natural_model_coefficients\n",
    "source_data_for_natural_model_distances = snakemake.output.source_data_for_natural_model_distances\n",
    "\n",
    "figure_for_natural_epitope_vs_oracle_models = snakemake.output.figure_for_natural_epitope_vs_oracle_models\n",
    "figure_for_natural_individual_models = snakemake.output.figure_for_natural_individual_models\n",
    "figure_for_natural_composite_models = snakemake.output.figure_for_natural_composite_models\n",
    "figure_for_natural_updated_models = snakemake.output.figure_for_natural_updated_models\n",
    "\n",
    "figure_for_simulated_cross_validation = snakemake.output.figure_for_simulated_cross_validation\n",
    "figure_for_natural_cross_validation = snakemake.output.figure_for_natural_cross_validation\n",
    "\n",
    "# Define parameters.\n",
    "simulated_sample = snakemake.params.simulated_sample\n",
    "natural_sample = snakemake.params.natural_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and define functions\n",
    "[back to top](#Summarize-models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import matplotlib as mpl\n",
    "from matplotlib.collections import LineCollection\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "register_matplotlib_converters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display figures at a reasonable default size.\n",
    "mpl.rcParams['figure.figsize'] = (6, 4)\n",
    "\n",
    "# Disable top and right spines.\n",
    "mpl.rcParams['axes.spines.top'] = False\n",
    "mpl.rcParams['axes.spines.right'] = False\n",
    "    \n",
    "# Display and save figures at higher resolution for presentations and manuscripts.\n",
    "mpl.rcParams['savefig.dpi'] = 200\n",
    "mpl.rcParams['figure.dpi'] = 200\n",
    "\n",
    "# Display text at sizes large enough for presentations and manuscripts.\n",
    "mpl.rcParams['font.weight'] = \"normal\"\n",
    "mpl.rcParams['axes.labelweight'] = \"normal\"\n",
    "mpl.rcParams['font.size'] = 18\n",
    "mpl.rcParams['axes.labelsize'] = 14\n",
    "mpl.rcParams['legend.fontsize'] = 12\n",
    "mpl.rcParams['xtick.labelsize'] = 14\n",
    "mpl.rcParams['ytick.labelsize'] = 14\n",
    "\n",
    "mpl.rc('text', usetex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "panel_labels_dict = {\n",
    "    \"weight\": \"bold\",\n",
    "    \"size\": 14\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['#d73027','#fc8d59','#fee090','#e0f3f8','#91bfdb','#4575b4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncols = 2\n",
    "color_by_predictor = {\n",
    "    'naive': '#000000',\n",
    "    'offspring': '#000000',\n",
    "    'normalized_fitness': '#000000',\n",
    "    'fitness': '#000000',\n",
    "    'ep': '#4575b4',\n",
    "    'ep_wolf': '#4575b4',\n",
    "    'ep_star': '#4575b4',\n",
    "    'ep_x': '#4575b4',\n",
    "    'ep_x_koel': '#4575b4',\n",
    "    'ep_x_wolf': '#4575b4',\n",
    "    'oracle_x': '#4575b4',\n",
    "    'rb': '#4575b4',\n",
    "    'cTiter': '#91bfdb',\n",
    "    'cTiter_x': '#91bfdb',\n",
    "    'cTiterSub': '#91bfdb',\n",
    "    'cTiterSub_star': '#91bfdb',\n",
    "    'cTiterSub_x': '#91bfdb',\n",
    "    'fra_cTiter_x': '#91bfdb',\n",
    "    'ne_star': '#2ca25f',\n",
    "    'dms_star': '#99d8c9',\n",
    "    \"dms_nonepitope\": \"#99d8c9\",\n",
    "    \"dms_entropy\": \"#99d8c9\",\n",
    "    'unnormalized_lbi': '#fc8d59',\n",
    "    'lbi': '#fc8d59',\n",
    "    'delta_frequency': '#d73027'\n",
    "}\n",
    "\n",
    "name_by_predictor = {\n",
    "    \"naive\": \"naive\",\n",
    "    \"offspring\": \"observed fitness\",\n",
    "    \"normalized_fitness\": \"true fitness\",\n",
    "    \"fitness\": \"estimated fitness\",\n",
    "    \"ep\": \"epitope mutations\",\n",
    "    \"ep_wolf\": \"Wolf epitope mutations\",\n",
    "    \"ep_star\": \"epitope ancestor\",\n",
    "    \"ep_x\": \"epitope antigenic novelty\",\n",
    "    \"ep_x_koel\": \"Koel epitope antigenic novelty\",\n",
    "    \"ep_x_wolf\": \"Wolf epitope antigenic novelty\",\n",
    "    \"oracle_x\": \"oracle antigenic novelty\",\n",
    "    \"rb\": \"Koel epitope mutations\",\n",
    "    \"cTiter\": \"antigenic advance\",\n",
    "    \"cTiter_x\": \"HI antigenic novelty\",\n",
    "    \"cTiterSub\": \"linear HI mut phenotypes\",\n",
    "    \"cTiterSub_star\": \"ancestral HI mut phenotypes\",\n",
    "    \"cTiterSub_x\": \"HI sub cross-immunity\",\n",
    "    \"fra_cTiter_x\": \"FRA antigenic novelty\",\n",
    "    \"ne_star\": \"mutational load\",\n",
    "    \"dms_star\": \"DMS mutational effects\",\n",
    "    \"dms_nonepitope\": \"DMS mutational load\",\n",
    "    \"dms_entropy\": \"DMS entropy\",\n",
    "    \"unnormalized_lbi\": \"unnormalized LBI\",\n",
    "    \"lbi\": \"LBI\",\n",
    "    \"delta_frequency\": \"delta frequency\"\n",
    "}\n",
    "\n",
    "predictors_to_drop = [\n",
    "    \"ep\",\n",
    "    \"cTiter\",\n",
    "    \"cTiterSub\",\n",
    "    \"cTiterSub_star\",\n",
    "    \"cTiterSub_x\"\n",
    "    #\"delta_frequency-ne_star\",\n",
    "    #\"lbi-ep_x-ne_star\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_individual_predictors_for_data_frame(df):\n",
    "    return [\n",
    "        predictor\n",
    "        for predictor in df[\"predictors\"].unique()\n",
    "        if \"-\" not in predictor and predictor != \"naive\"\n",
    "    ]\n",
    "\n",
    "def get_composite_predictors_for_data_frame(df):\n",
    "    return [\n",
    "        predictor\n",
    "        for predictor in df[\"predictors\"].unique()\n",
    "        if \"-\" in predictor\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_accuracy_and_coefficients_for_build(errors_by_time_df, coefficients_by_time_df, predictors, rotation=30,\n",
    "                                             years_fmt_string=\"%Y\", date_fmt_string=\"%Y-%m-%d\", height=12, width=12,\n",
    "                                             text_vertical_padding=0.12, hspace=0.1, wspace=0.2, max_predictor_name_length=55,\n",
    "                                             share_y=True, max_coefficient=None, min_normal_error=None, max_normal_error=None,\n",
    "                                             error_attribute=\"validation_error\",\n",
    "                                             naive_attribute=\"null_validation_error\",\n",
    "                                             optimal_attribute=\"optimal_validation_error\",\n",
    "                                             distance_axis_label=\"Distance to\\nfuture (AAs)\",\n",
    "                                             coefficient_axis_label=\"Coefficient\",\n",
    "                                             distance_tick_multiple=2):\n",
    "    # Determine bounds for given data to set axes domains and ranges.\n",
    "    std_normal_error = errors_by_time_df[error_attribute].std()\n",
    "    \n",
    "    if max_normal_error is None:\n",
    "        max_normal_error = errors_by_time_df[error_attribute].max()\n",
    "        max_normal_error += 2.0 * std_normal_error\n",
    "\n",
    "    if min_normal_error is None:\n",
    "        min_normal_error = errors_by_time_df[optimal_attribute].min()\n",
    "        \n",
    "    min_coefficient = coefficients_by_time_df[\"coefficient\"].min()\n",
    "    \n",
    "    if max_coefficient is None:\n",
    "        max_coefficient = coefficients_by_time_df[\"coefficient\"].max() + 2\n",
    "\n",
    "    min_date = errors_by_time_df[\"validation_timepoint\"].min() - pd.DateOffset(months=6)\n",
    "    max_date = errors_by_time_df[\"validation_timepoint\"].max() + pd.DateOffset(months=6)\n",
    "    \n",
    "    nrows = len(predictors)\n",
    "    \n",
    "    naive_error_df = errors_by_time_df[errors_by_time_df[\"predictors\"] == \"naive\"].copy()\n",
    "    naive_validation_error_df = naive_error_df[naive_error_df[\"error_type\"] == \"validation\"].copy()\n",
    "    naive_test_error_df = naive_error_df[naive_error_df[\"error_type\"] == \"test\"].copy()\n",
    "    total_validation_timepoints = naive_validation_error_df.shape[0]\n",
    "    total_timepoints = naive_error_df.shape[0]\n",
    "    \n",
    "    fig, axes = plt.subplots(figsize=(width, height), facecolor='w')\n",
    "    gs = gridspec.GridSpec(\n",
    "        nrows=nrows,\n",
    "        ncols=ncols,\n",
    "        hspace=hspace,\n",
    "        wspace=wspace\n",
    "    )\n",
    "\n",
    "    years = mdates.YearLocator(3)\n",
    "    years_fmt = mdates.DateFormatter(years_fmt_string)\n",
    "    months = mdates.MonthLocator()\n",
    "    \n",
    "    # Get the start and end date for test data to enable visual delineation of these later data.\n",
    "    test_start_date, test_end_date = naive_test_error_df[\"validation_timepoint\"].aggregate([\"min\", \"max\"]).values\n",
    "\n",
    "    for i, predictor in enumerate(predictors):\n",
    "        error_df = errors_by_time_df[errors_by_time_df[\"predictors\"] == predictor].copy()\n",
    "        validation_error_df = error_df[error_df[\"error_type\"] == \"validation\"].copy()\n",
    "        test_error_df = error_df[error_df[\"error_type\"] == \"test\"].copy()\n",
    "        \n",
    "        coefficient_df = coefficients_by_time_df[coefficients_by_time_df[\"predictors\"] == predictor].copy()\n",
    "        validation_coefficient_df = coefficient_df[coefficient_df[\"error_type\"] == \"validation\"].copy()\n",
    "        test_coefficient_df = coefficient_df[coefficient_df[\"error_type\"] == \"test\"].copy()\n",
    "        \n",
    "        composite_predictors = predictor.split(\"-\")\n",
    "        composite_predictors_name = \" + \".join([name_by_predictor[predictor_name] for predictor_name in composite_predictors])\n",
    "        if len(composite_predictors_name) > max_predictor_name_length:\n",
    "            predictor_name_spacing = \"\\n\"\n",
    "        else:\n",
    "            predictor_name_spacing = \" \"\n",
    "\n",
    "        distance_ax = plt.subplot(gs[i, 1])    \n",
    "        distance_ax.set_xlabel(\"Date\")\n",
    "        distance_ax.set_ylabel(distance_axis_label)\n",
    "\n",
    "        distance_ax.axhline(\n",
    "            y=0.0,\n",
    "            color=\"#cccccc\"\n",
    "        )\n",
    "\n",
    "        # Plot validation data.        \n",
    "        distance_ax.plot(\n",
    "            pd.to_datetime(validation_error_df[\"validation_timepoint\"]).astype(np.datetime64),\n",
    "            validation_error_df[error_attribute],\n",
    "            \"o-\",\n",
    "            color=\"#000000\",\n",
    "            label=\"validation: %.2f +/- %.2f\" % (validation_error_df[error_attribute].mean(), validation_error_df[error_attribute].std())\n",
    "        )\n",
    "        \n",
    "        # Plot distance from current timepoint to future.\n",
    "        distance_ax.plot(\n",
    "            pd.to_datetime(validation_error_df[\"validation_timepoint\"]).astype(np.datetime64),\n",
    "            validation_error_df[naive_attribute],\n",
    "            \"-\",\n",
    "            color=\"#cccccc\",\n",
    "            label=\"\",\n",
    "            zorder=-10\n",
    "        )\n",
    "        \n",
    "        # Plot optimal distance from current timepoint to future for any model.\n",
    "        distance_ax.plot(\n",
    "            pd.to_datetime(validation_error_df[\"validation_timepoint\"]).astype(np.datetime64),\n",
    "            validation_error_df[optimal_attribute],\n",
    "            \"-\",\n",
    "            color=\"#999999\",\n",
    "            label=\"\",\n",
    "            zorder=-10\n",
    "        )\n",
    "        \n",
    "        # Plot test data.\n",
    "        if test_error_df.shape[0] > 0:\n",
    "            model_test_distance_handle_output = distance_ax.plot(\n",
    "                pd.to_datetime(test_error_df[\"validation_timepoint\"]).astype(np.datetime64),\n",
    "                test_error_df[error_attribute],\n",
    "                \"o-\",\n",
    "                fillstyle=\"none\",\n",
    "                color=\"#000000\",\n",
    "                label=\"test: %.2f +/- %.2f\" % (test_error_df[error_attribute].mean(), test_error_df[error_attribute].std())\n",
    "            )\n",
    "            \n",
    "            # Plot distance from current timepoint to future.\n",
    "            distance_ax.plot(\n",
    "                pd.to_datetime(test_error_df[\"validation_timepoint\"]).astype(np.datetime64),\n",
    "                test_error_df[naive_attribute],\n",
    "                \"-\",\n",
    "                fillstyle=\"none\",\n",
    "                color=\"#cccccc\",\n",
    "                label=\"\",\n",
    "                zorder=-10\n",
    "            )\n",
    "            \n",
    "            # Plot optimal distance from current timepoint to future for any model.\n",
    "            distance_ax.plot(\n",
    "                pd.to_datetime(test_error_df[\"validation_timepoint\"]).astype(np.datetime64),\n",
    "                test_error_df[optimal_attribute],\n",
    "                \"-\",\n",
    "                fillstyle=\"none\",\n",
    "                color=\"#999999\",\n",
    "                label=\"\",\n",
    "                zorder=-10\n",
    "            )\n",
    "        \n",
    "        distance_ax.legend(\n",
    "            loc=(0.01, 0.92),\n",
    "            frameon=False,\n",
    "            fontsize=12,\n",
    "            ncol=2\n",
    "        )\n",
    "\n",
    "        distance_ax.set_xlim(min_date, max_date)\n",
    "        \n",
    "        distance_ax.set_ylim(min_normal_error, max_normal_error)\n",
    "        distance_ax.xaxis.set_major_locator(years)\n",
    "        distance_ax.xaxis.set_major_formatter(years_fmt)\n",
    "        distance_ax.xaxis.set_minor_locator(months)\n",
    "        distance_ax.format_xdata = mdates.DateFormatter(date_fmt_string)\n",
    "        \n",
    "        distance_ax.yaxis.set_major_locator(ticker.MultipleLocator(distance_tick_multiple))\n",
    "        distance_ax.tick_params(which='major', width=1.00, length=5)\n",
    "\n",
    "        coefficient_ax = plt.subplot(gs[i, 0])\n",
    "        coefficient_ax.set_xlabel(\"Date\")\n",
    "        coefficient_ax.set_ylabel(coefficient_axis_label)\n",
    "        \n",
    "        if share_y:\n",
    "            coefficient_ax.set_ylim(min_coefficient - 1, max_coefficient)\n",
    "\n",
    "        coefficient_ax.axhline(\n",
    "            y=0.0,\n",
    "            color=\"#999999\"\n",
    "        )\n",
    "\n",
    "        # Plot validation coefficients\n",
    "        for predictor, predictor_coefficient_df in validation_coefficient_df.groupby(\"predictor\"):\n",
    "            coefficient_ax.plot(\n",
    "                predictor_coefficient_df[\"validation_timepoint\"],\n",
    "                predictor_coefficient_df[\"coefficient\"],\n",
    "                \"o-\",\n",
    "                color=color_by_predictor[predictor],\n",
    "                label=\"%s: %.2f +/- %.2f\" % (\n",
    "                    name_by_predictor[predictor],\n",
    "                    predictor_coefficient_df[\"coefficient\"].mean(),\n",
    "                    predictor_coefficient_df[\"coefficient\"].std()\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        number_of_coefficients = validation_coefficient_df[\"predictor\"].drop_duplicates().shape[0]\n",
    "        y_position_by_number_of_coefficients = {\n",
    "            1: 0.92,\n",
    "            2: 0.75,\n",
    "            3: 0.6\n",
    "        }\n",
    "        coefficient_legend = coefficient_ax.legend(\n",
    "            loc=(0.01, y_position_by_number_of_coefficients[number_of_coefficients]),\n",
    "            frameon=False,\n",
    "            fontsize=12\n",
    "        )\n",
    "        \n",
    "        for legend_text in coefficient_legend.get_texts():\n",
    "            legend_text.set_horizontalalignment(\"left\")\n",
    "            legend_text.set_verticalalignment(\"baseline\")\n",
    "\n",
    "        # Plot fixed coefficients for testing\n",
    "        for predictor, predictor_coefficient_df in test_coefficient_df.groupby(\"predictor\"):\n",
    "            coefficient_ax.plot(\n",
    "                predictor_coefficient_df[\"validation_timepoint\"],\n",
    "                predictor_coefficient_df[\"coefficient\"],\n",
    "                \"o-\",\n",
    "                fillstyle=\"none\",\n",
    "                color=color_by_predictor[predictor],\n",
    "                label=\"%s: %.2f +/- %.2f\" % (\n",
    "                    name_by_predictor[predictor],\n",
    "                    predictor_coefficient_df[\"coefficient\"].mean(),\n",
    "                    predictor_coefficient_df[\"coefficient\"].std()\n",
    "                )\n",
    "            )\n",
    "\n",
    "        coefficient_ax.set_xlim(min_date, max_date)\n",
    "        coefficient_ax.xaxis.set_major_locator(years)\n",
    "        coefficient_ax.xaxis.set_major_formatter(years_fmt)\n",
    "        coefficient_ax.xaxis.set_minor_locator(months)\n",
    "        coefficient_ax.format_xdata = mdates.DateFormatter(date_fmt_string)\n",
    "\n",
    "    fig.autofmt_xdate(rotation=rotation, ha=\"center\")\n",
    "    gs.tight_layout(fig, h_pad=hspace)\n",
    "    # show x-axis tick lines\n",
    "    \n",
    "    return (fig, axes, gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_table(errors_df, coefficients_df, text_width=1.0, include_coefficients=True):\n",
    "    error_metric = \"validation_error\"\n",
    "    \n",
    "    coefficient_columns = [\"model\", \"predictor\", \"coefficient_mean\", \"coefficient_std\"]\n",
    "    model_selection_coefficients = coefficients_df.groupby([\"model\", \"predictor\"], sort=False).aggregate({\n",
    "        \"coefficient\": [\"mean\", \"std\"]\n",
    "    }).reset_index()\n",
    "    model_selection_coefficients.columns = coefficient_columns\n",
    "    \n",
    "    model_selection_errors = errors_df.groupby(\"model\").aggregate({\n",
    "        error_metric: [\"mean\", \"std\"],\n",
    "        \"model_better_than_naive\": [\"sum\", \"mean\"]\n",
    "    }).sort_values((error_metric, \"mean\"), ascending=False)\n",
    "    # .query(\"model != 'naive'\")\n",
    "    \n",
    "    model_selection_errors.loc[:, (\"model_better_than_naive\", \"sum\")] = model_selection_errors[(\"model_better_than_naive\", \"sum\")].astype(int)\n",
    "    \n",
    "    columns = [\n",
    "        \"model\",\n",
    "        \"%s_mean\" % error_metric,\n",
    "        \"%s_std\" % error_metric,\n",
    "        \"model_better_count\",\n",
    "        \"model_better_proportion\"\n",
    "    ]\n",
    "    model_selection_errors = np.around(model_selection_errors, 2).reset_index()\n",
    "    model_selection_errors.columns = columns\n",
    "    model_selection_errors = model_selection_errors.sort_values(\"%s_mean\" % error_metric, ascending=True)\n",
    "        \n",
    "    if include_coefficients:\n",
    "        model_selection = model_selection_errors.merge(\n",
    "            model_selection_coefficients,\n",
    "            on=[\"model\"]\n",
    "        )\n",
    "\n",
    "        model_selection[\"coefficients\"] = model_selection.apply(\n",
    "            lambda row: \"%.2f +/- %.2f\" % (row[\"coefficient_mean\"], row[\"coefficient_std\"]),\n",
    "            axis=1\n",
    "        )\n",
    "        \n",
    "        simple_model_selection_columns = [\"model\", \"coefficients\", error_metric, \"model_better\"]\n",
    "    else:\n",
    "        model_selection = model_selection_errors.copy()\n",
    "        simple_model_selection_columns = [\"model\", error_metric, \"model_better\"]\n",
    "\n",
    "    model_selection[error_metric] = model_selection.apply(\n",
    "        lambda row: \"%.2f +/- %.2f\" % (row[\"%s_mean\" % error_metric], row[\"%s_std\" % error_metric]),\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    model_selection[\"model_better\"] = model_selection.apply(\n",
    "        lambda row: \"%i (%i\\%%)\" % (row[\"model_better_count\"], int(row[\"model_better_proportion\"] * 100)),\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    simple_model_selection = []\n",
    "    for model, model_df in model_selection.loc[:, simple_model_selection_columns].groupby(\"model\", sort=False):\n",
    "        new_model_predictors = model.split(\" + \")\n",
    "        \n",
    "        if include_coefficients:\n",
    "            new_coefficients = model_df[\"coefficients\"].values\n",
    "        \n",
    "        for i in range(len(new_model_predictors)):\n",
    "            if i == 0:\n",
    "                if len(new_model_predictors) > 1:\n",
    "                    new_model_predictor = new_model_predictors[i] + \" +\"\n",
    "                else:\n",
    "                    new_model_predictor = new_model_predictors[i]\n",
    "                    \n",
    "                new_validation_error = model_df[error_metric].values[0]\n",
    "                new_model_better = model_df[\"model_better\"].values[0]\n",
    "            else:\n",
    "                new_model_predictor = \"\\hspace{3mm}\" + new_model_predictors[i]\n",
    "                new_validation_error = \"\"\n",
    "                new_model_better = \"\"\n",
    "                \n",
    "            record = {\n",
    "                \"model\": new_model_predictor,\n",
    "                error_metric: new_validation_error,\n",
    "                \"model_better\": new_model_better\n",
    "            }\n",
    "            \n",
    "            if include_coefficients:\n",
    "                record[\"coefficients\"] = new_coefficients[i]\n",
    "                \n",
    "            simple_model_selection.append(record)\n",
    "\n",
    "    latex_columns = [\n",
    "        \"Model\",\n",
    "        \"\\makecell{Distance to \\\\\\\\ future (AAs)}\",\n",
    "        \"\\makecell[l]{Model $>$ naive \\\\\\\\ (N=%i)}\" % errors_df[\"validation_timepoint\"].unique().shape[0]\n",
    "    ]\n",
    "    column_format = \"lrl\"\n",
    "    \n",
    "    if include_coefficients:\n",
    "        latex_columns.insert(1, \"Coefficients\")\n",
    "        column_format = \"lrrl\"\n",
    "        \n",
    "    simple_model_selection = pd.DataFrame(simple_model_selection, columns=simple_model_selection_columns)\n",
    "    simple_model_selection.columns = latex_columns\n",
    "    \n",
    "    # Update pandas options for maximum column width to display so longer cells do not get truncates in LaTeX.\n",
    "    with pd.option_context(\"max_colwidth\", 1000):\n",
    "        simple_model_selection_table = simple_model_selection.to_latex(index=False, escape=False, column_format=column_format).replace(\n",
    "            \"tabular}\",\n",
    "            \"tabular*}\"\n",
    "        ).replace(\n",
    "            \"{tabular*}{\",\n",
    "            \"{tabular*}{%s\\\\textwidth}{\" % text_width\n",
    "        )\n",
    "        \n",
    "    return simple_model_selection_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_values = pd.read_csv(bootstrap_p_values_file, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_values.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_by_time_df = pd.read_csv(errors_file, sep=\"\\t\", parse_dates=[\"validation_timepoint\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_by_time_df = errors_by_time_df.merge(\n",
    "    p_values,\n",
    "    on=[\"sample\", \"error_type\", \"predictors\"],\n",
    "    how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_by_time_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distinct_samples_with_errors = errors_by_time_df[\"sample\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distinct_samples_with_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert simulated_sample in distinct_samples_with_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert natural_sample in distinct_samples_with_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_by_time_df = errors_by_time_df[~errors_by_time_df[\"predictors\"].isin(predictors_to_drop)].copy()\n",
    "errors_by_time_df[\"model_improvement\"] = errors_by_time_df[\"null_validation_error\"] - errors_by_time_df[\"validation_error\"]\n",
    "errors_by_time_df[\"log2_model_improvement\"] = np.log2(errors_by_time_df[\"null_validation_error\"] / errors_by_time_df[\"validation_error\"])\n",
    "errors_by_time_df[\"relative_improvement\"] = (\n",
    "    errors_by_time_df[\"null_validation_error\"] - errors_by_time_df[\"validation_error\"]\n",
    ") / errors_by_time_df[\"null_validation_error\"]\n",
    "errors_by_time_df[\"proportion_by_model\"] = errors_by_time_df[\"validation_error\"] / errors_by_time_df[\"null_validation_error\"]\n",
    "errors_by_time_df[\"proportion_explained\"] = 1 - (errors_by_time_df[\"validation_error\"] / errors_by_time_df[\"null_validation_error\"])\n",
    "errors_by_time_df[\"distance_from_future\"] = errors_by_time_df[\"average_distance_to_future\"] - errors_by_time_df[\"average_diversity_in_future\"]\n",
    "\n",
    "simulated_errors_by_time_df = errors_by_time_df[errors_by_time_df[\"sample\"] == simulated_sample].copy()\n",
    "natural_errors_by_time_df = errors_by_time_df[errors_by_time_df[\"sample\"] == natural_sample].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_errors_by_time_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "natural_errors_by_time_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients_by_time_df = pd.read_csv(coefficients_file, sep=\"\\t\", parse_dates=[\"validation_timepoint\"])\n",
    "coefficients_by_time_df = coefficients_by_time_df[~coefficients_by_time_df[\"predictors\"].isin(predictors_to_drop)].copy()\n",
    "\n",
    "simulated_coefficients_by_time_df = coefficients_by_time_df[coefficients_by_time_df[\"sample\"] == simulated_sample].copy()\n",
    "natural_coefficients_by_time_df = coefficients_by_time_df[coefficients_by_time_df[\"sample\"] == natural_sample].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_coefficients_by_time_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "natural_coefficients_by_time_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_individual_predictors_for_data_frame(simulated_errors_by_time_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_composite_predictors_for_data_frame(simulated_errors_by_time_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_individual_predictors_for_data_frame(natural_errors_by_time_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_composite_predictors_for_data_frame(natural_errors_by_time_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_errors_by_time_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "natural_errors_by_time_df.query(\"predictors == 'cTiter_x'\").loc[:, [\"validation_timepoint\", \"validation_error\", \"null_validation_error\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of models for simulated populations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_errors_by_time_df[\"model\"] = simulated_errors_by_time_df[\"predictors\"].apply(\n",
    "    lambda predictor: \" + \".join([name_by_predictor.get(predictor_name, predictor_name) for predictor_name in predictor.split(\"-\")])\n",
    ")\n",
    "simulated_coefficients_by_time_df[\"model\"] = simulated_coefficients_by_time_df[\"predictors\"].apply(\n",
    "    lambda predictor: \" + \".join([name_by_predictor.get(predictor_name, predictor_name) for predictor_name in predictor.split(\"-\")])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_errors_by_time_df[\"model_better_than_naive\"] = (simulated_errors_by_time_df[\"model_improvement\"] > 0)\n",
    "simulated_errors_by_time_df[\"relative_improvement\"] = (\n",
    "    simulated_errors_by_time_df[\"validation_error\"] / simulated_errors_by_time_df[\"null_validation_error\"]\n",
    ") - 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_errors_by_time_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_errors_by_time_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_validation_errors_by_time_df = simulated_errors_by_time_df.query(\"error_type == 'validation'\").copy()\n",
    "simulated_validation_coefficients_by_time_df = simulated_coefficients_by_time_df.query(\"error_type == 'validation'\").copy()\n",
    "\n",
    "simulated_test_errors_by_time_df = simulated_errors_by_time_df.query(\"error_type == 'test'\").copy()\n",
    "simulated_test_coefficients_by_time_df = simulated_coefficients_by_time_df.query(\"error_type == 'test'\").copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model validation table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_template_header = r\"\"\"\n",
    "\\begin{tabular*}{1.1\\textwidth}{lrllrr}\n",
    "\\toprule\n",
    "        &                 & \\multicolumn{2}{c}{Distance to future (AAs)} & \\multicolumn{2}{c}{Model $>$ naive} \\\\\n",
    "  Model &    \\makecell{Coefficients} & \\makecell{Validation} & \\makecell{Test} & \\makecell{Validation} & \\makecell{Test} \\\\\n",
    "\\midrule\n",
    "\"\"\"\n",
    "\n",
    "table_template_first_row = r\"{predictor} & {coefficient_mean:.2f} +/- {coefficient_std:.2f} & {mean_error_validation:.2f} +/- {std_error_validation:.2f}{significance_mark_validation} & {mean_error_test:.2f} +/- {std_error_test:.2f}{significance_mark_test} & {model_better_count_validation} ({model_better_percentage_validation}\\%) & {model_better_count_test} ({model_better_percentage_test}\\%) \\\\\"\n",
    "\n",
    "table_template_next_row = r\"\\hspace{{5mm}} + {predictor} & {coefficient_mean:.2f} +/- {coefficient_std:.2f} & & & & \\\\\"\n",
    "\n",
    "table_template_footer = r\"\"\"\n",
    "\\bottomrule\n",
    "\\end{tabular*}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_significance_mark(model_error_record):\n",
    "    p_value = model_error_record[\"p_value\"]\n",
    "    predictor = model_error_record[\"model\"]\n",
    "    \n",
    "    if predictor == \"naive\":\n",
    "        return \"\"\n",
    "    elif np.isnan(p_value):\n",
    "        return \"\\^\"\n",
    "    elif p_value < 0.05:\n",
    "        return \"*\"\n",
    "    else:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_error_data_frame(errors_df):\n",
    "    model_errors = errors_df.groupby(\"model\").aggregate({\n",
    "        \"validation_error\": [\"mean\", \"std\"],\n",
    "        \"model_better_than_naive\": [\"sum\", \"mean\"],\n",
    "        \"p_value\": [\"first\"]\n",
    "    }).sort_values((\"validation_error\", \"mean\"), ascending=True).reset_index()\n",
    "    \n",
    "    columns = [\n",
    "        \"model\",\n",
    "        \"mean_error\",\n",
    "        \"std_error\",\n",
    "        \"model_better_count\",\n",
    "        \"model_better_proportion\",\n",
    "        \"p_value\"\n",
    "    ]\n",
    "    model_errors.columns = columns\n",
    "    model_errors[\"model_better_count\"] = model_errors[\"model_better_count\"].astype(int)\n",
    "    model_errors[\"model_better_percentage\"] = np.around(model_errors[\"model_better_proportion\"] * 100, 0).astype(int)\n",
    "    model_errors[\"significance_mark\"] = model_errors.apply(make_significance_mark, axis=1)\n",
    "    \n",
    "    return model_errors\n",
    "\n",
    "def group_coefficients_data_frame(coefficients_df):\n",
    "    coefficient_columns = [\"model\", \"predictor\", \"coefficient_mean\", \"coefficient_std\"]\n",
    "    model_coefficients = coefficients_df.groupby([\"model\", \"predictor\"], sort=False).aggregate({\n",
    "        \"coefficient\": [\"mean\", \"std\"]\n",
    "    }).reset_index()\n",
    "    model_coefficients.columns = coefficient_columns\n",
    "    model_coefficients[\"predictor\"] = model_coefficients[\"predictor\"].map(name_by_predictor)\n",
    "\n",
    "    return model_coefficients\n",
    "\n",
    "def prepare_complete_table(coefficients_df, errors_df, test_errors_df):\n",
    "    model_coefficients = group_coefficients_data_frame(coefficients_df)\n",
    "    model_selection_errors = group_error_data_frame(errors_df)\n",
    "    model_test_errors = group_error_data_frame(test_errors_df)\n",
    "    \n",
    "    model_errors = model_selection_errors.merge(\n",
    "        model_test_errors,\n",
    "        on=\"model\",\n",
    "        suffixes=[\"_validation\", \"_test\"]\n",
    "    )\n",
    "    \n",
    "    model_summary = np.around(model_errors.merge(\n",
    "        model_coefficients,\n",
    "        on=\"model\"\n",
    "    ), 2)\n",
    "    \n",
    "    rows = [table_template_header]\n",
    "    for model, model_df in model_summary.groupby(\"model\", sort=False):\n",
    "        for i, record in enumerate(model_df.to_dict(orient=\"records\")):\n",
    "            if i == 0:\n",
    "                rows.append(table_template_first_row.format(**record))\n",
    "            else:\n",
    "                rows.append(table_template_next_row.format(**record))\n",
    "            \n",
    "    rows.append(table_template_footer)\n",
    "\n",
    "    return \"\\n\".join(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 1. Simulated model performance table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_simulated_model_selection_table = prepare_complete_table(\n",
    "    simulated_validation_coefficients_by_time_df,\n",
    "    simulated_validation_errors_by_time_df,\n",
    "    simulated_test_errors_by_time_df\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(simple_simulated_model_selection_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(table_for_simulated_model_selection, \"w\") as oh:\n",
    "    oh.write(simple_simulated_model_selection_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "Build a clean data frame of the table's source data for export."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients_source_file_columns = OrderedDict([\n",
    "    (\"model\", \"model\"),\n",
    "    (\"predictor\", \"predictor\"),\n",
    "    (\"validation_timepoint\", \"timepoint\"),\n",
    "    (\"coefficient\", \"coefficient\"),\n",
    "])\n",
    "\n",
    "distances_source_file_columns = OrderedDict([\n",
    "    (\"error_type\", \"error_type\"),\n",
    "    (\"model\", \"model\"),\n",
    "    (\"validation_timepoint\", \"timepoint\"),\n",
    "    (\"validation_error\", \"model_distance_to_future\"),\n",
    "    (\"null_validation_error\", \"naive_distance_to_future\"),\n",
    "    (\"optimal_validation_error\", \"optimal_distance_to_future\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_coefficients_source_data = simulated_validation_coefficients_by_time_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_coefficients_source_data = np.around(\n",
    "    simulated_coefficients_source_data.loc[\n",
    "        simulated_coefficients_source_data[\"model\"] != \"naive\",\n",
    "        tuple(coefficients_source_file_columns.keys())\n",
    "    ].copy().rename(columns=coefficients_source_file_columns),\n",
    "    3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_coefficients_source_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_coefficients_source_data.to_csv(\n",
    "    source_data_for_simulated_model_coefficients,\n",
    "    header=True,\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_distances_source_data = pd.concat([\n",
    "    simulated_validation_errors_by_time_df,\n",
    "    simulated_test_errors_by_time_df\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_distances_source_data = np.around(\n",
    "    simulated_distances_source_data.loc[\n",
    "        simulated_distances_source_data[\"model\"] != \"naive\",\n",
    "        tuple(distances_source_file_columns.keys())\n",
    "    ].copy().rename(columns=distances_source_file_columns),\n",
    "    3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_distances_source_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_distances_source_data.to_csv(\n",
    "    source_data_for_simulated_model_distances,\n",
    "    header=True,\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Figure 2. Simulated model results for controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_errors_by_time_df[\"centered_validation_error\"] = (\n",
    "    simulated_errors_by_time_df[\"validation_error\"] - simulated_errors_by_time_df[\"optimal_validation_error\"]\n",
    ")\n",
    "\n",
    "simulated_errors_by_time_df[\"centered_null_validation_error\"] = (\n",
    "    simulated_errors_by_time_df[\"null_validation_error\"] - simulated_errors_by_time_df[\"optimal_validation_error\"]\n",
    ")\n",
    "\n",
    "simulated_errors_by_time_df[\"centered_optimal_validation_error\"] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes, gs = plot_model_accuracy_and_coefficients_for_build(\n",
    "    simulated_errors_by_time_df,\n",
    "    simulated_coefficients_by_time_df,\n",
    "    [\"normalized_fitness\"],\n",
    "    rotation=0,\n",
    "    years_fmt_string=\"%y\",\n",
    "    date_fmt_string=\"%y-%m\",\n",
    "    height=3,\n",
    "    hspace=0.1,\n",
    "    share_y=True,\n",
    "    max_coefficient=13,\n",
    "    max_normal_error=13\n",
    ")\n",
    "\n",
    "plt.figtext(0.0, 0.9, \"A\", **panel_labels_dict)\n",
    "plt.figtext(0.49, 0.9, \"B\", **panel_labels_dict)\n",
    "\n",
    "plt.savefig(figure_for_simulated_model_controls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "Summarize optimal distance to the future possible from the current population. These values represent the lower bound possible for any given model based on the number of amino acid mutations that accumulate during one year of evolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_errors_by_time_df.query(\"predictors == 'naive'\").groupby(\"error_type\")[\"optimal_validation_error\"].aggregate([\n",
    "    \"mean\",\n",
    "    \"std\"\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Figure 3. Simulated model results for individual predictors and best composite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes, gs = plot_model_accuracy_and_coefficients_for_build(\n",
    "    simulated_errors_by_time_df,\n",
    "    simulated_coefficients_by_time_df,\n",
    "    [\"ep_x\", \"ne_star\", \"lbi\", \"delta_frequency\", \"lbi-ne_star\"],\n",
    "    rotation=0,\n",
    "    years_fmt_string=\"%y\",\n",
    "    date_fmt_string=\"%y-%m\",\n",
    "    height=10,\n",
    "    hspace=0.1,\n",
    "    share_y=True,\n",
    "    max_coefficient=7,\n",
    "    max_normal_error=16\n",
    ")\n",
    "\n",
    "plt.figtext(0.0, 0.98, \"A\", **panel_labels_dict)\n",
    "plt.figtext(0.49, 0.98, \"B\", **panel_labels_dict)\n",
    "\n",
    "plt.savefig(figure_for_simulated_individual_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes, gs = plot_model_accuracy_and_coefficients_for_build(\n",
    "    simulated_errors_by_time_df,\n",
    "    simulated_coefficients_by_time_df,\n",
    "    get_composite_predictors_for_data_frame(simulated_errors_by_time_df),\n",
    "    rotation=0,\n",
    "    years_fmt_string=\"%y\",\n",
    "    date_fmt_string=\"%y-%m\",\n",
    "    height=6,\n",
    "    max_coefficient=5.0,\n",
    "    max_normal_error=16\n",
    ")\n",
    "\n",
    "plt.figtext(0.0, 0.97, \"A\", **panel_labels_dict)\n",
    "plt.figtext(0.49, 0.97, \"B\", **panel_labels_dict)\n",
    "\n",
    "plt.savefig(figure_for_simulated_composite_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of models for natural populations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_of_individual_predictors = [\n",
    "    \"ep_x\",\n",
    "    \"cTiter_x\",\n",
    "    \"ne_star\",\n",
    "    \"dms_star\",\n",
    "    \"lbi\",\n",
    "    \"delta_frequency\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "composite_models = [\n",
    "    \"cTiter_x-ne_star\",\n",
    "    \"ne_star-lbi\",\n",
    "    \"cTiter_x-ne_star-lbi\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "natural_errors_by_time_df[\"validation_timepoint\"].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "natural_errors_by_time_df[\"model\"] = natural_errors_by_time_df[\"predictors\"].apply(\n",
    "    lambda predictor: \" + \".join([name_by_predictor.get(predictor_name, predictor_name) for predictor_name in predictor.split(\"-\")])\n",
    ")\n",
    "natural_coefficients_by_time_df[\"model\"] = natural_coefficients_by_time_df[\"predictors\"].apply(\n",
    "    lambda predictor: \" + \".join([name_by_predictor.get(predictor_name, predictor_name) for predictor_name in predictor.split(\"-\")])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "natural_errors_by_time_df[\"model_better_than_naive\"] = (natural_errors_by_time_df[\"model_improvement\"] > 0)\n",
    "natural_errors_by_time_df[\"relative_improvement\"] = (\n",
    "    natural_errors_by_time_df[\"validation_error\"] / natural_errors_by_time_df[\"null_validation_error\"]\n",
    ") - 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "natural_validation_errors_by_time_df = natural_errors_by_time_df.query(\"error_type == 'validation'\").copy()\n",
    "natural_validation_coefficients_by_time_df = natural_coefficients_by_time_df.query(\"error_type == 'validation'\").copy()\n",
    "\n",
    "natural_test_errors_by_time_df = natural_errors_by_time_df.query(\"error_type == 'test'\").copy()\n",
    "natural_test_coefficients_by_time_df = natural_coefficients_by_time_df.query(\"error_type == 'test'\").copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_of_natural_validation_errors_by_time_df = natural_validation_errors_by_time_df[\n",
    "    natural_validation_errors_by_time_df[\"predictors\"].isin([\"naive\"] + subset_of_individual_predictors + composite_models)\n",
    "].copy()\n",
    "\n",
    "subset_of_natural_validation_coefficients_by_time_df = natural_validation_coefficients_by_time_df[\n",
    "    natural_validation_coefficients_by_time_df[\"predictors\"].isin([\"naive\"] + subset_of_individual_predictors + composite_models)\n",
    "].copy()\n",
    "\n",
    "subset_of_natural_test_errors_by_time_df = natural_test_errors_by_time_df[\n",
    "    natural_test_errors_by_time_df[\"predictors\"].isin([\"naive\"] + subset_of_individual_predictors + composite_models)\n",
    "].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "natural_errors_by_time_df.query(\"predictors == 'naive'\").groupby(\"error_type\")[\"optimal_validation_error\"].aggregate([\n",
    "    \"mean\",\n",
    "    \"std\"\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 2. Natural model performance table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_natural_model_selection_table = prepare_complete_table(\n",
    "    subset_of_natural_validation_coefficients_by_time_df,\n",
    "    subset_of_natural_validation_errors_by_time_df,\n",
    "    subset_of_natural_test_errors_by_time_df\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(subset_natural_model_selection_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(table_for_natural_model_selection, \"w\") as oh:\n",
    "    oh.write(subset_natural_model_selection_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table S3. Complete natural model performance table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a separate table with all models including those we do not discuss in the manuscript."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_template_header = r\"\"\"\n",
    "\\begin{tabular*}{1.1\\textwidth}{lrllrr}\n",
    "\\toprule\n",
    "        &                 & \\multicolumn{2}{c}{Distance to future (AAs)} & \\multicolumn{2}{c}{Model $>$ naive} \\\\\n",
    "  Model &    \\makecell{Coefficients} & \\makecell{Validation} & \\makecell{Test} & \\makecell{Validation} & \\makecell{Test} \\\\\n",
    "\\midrule\n",
    "\"\"\"\n",
    "\n",
    "complete_natural_model_selection_table = prepare_complete_table(\n",
    "    natural_validation_coefficients_by_time_df,\n",
    "    natural_validation_errors_by_time_df,\n",
    "    natural_test_errors_by_time_df\n",
    ")\n",
    "\n",
    "with open(table_for_natural_model_complete_selection, \"w\") as oh:\n",
    "    oh.write(complete_natural_model_selection_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "Build a clean data frame of the table's source data for export."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "natural_coefficients_source_data = natural_validation_coefficients_by_time_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "natural_coefficients_source_data = np.around(\n",
    "    natural_coefficients_source_data.loc[\n",
    "        natural_coefficients_source_data[\"model\"] != \"naive\",\n",
    "        tuple(coefficients_source_file_columns.keys())\n",
    "    ].copy().rename(columns=coefficients_source_file_columns),\n",
    "    3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "natural_coefficients_source_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "natural_coefficients_source_data.to_csv(\n",
    "    source_data_for_natural_model_coefficients,\n",
    "    header=True,\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "natural_distances_source_data = pd.concat([\n",
    "    natural_validation_errors_by_time_df,\n",
    "    natural_test_errors_by_time_df\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "natural_distances_source_data = np.around(\n",
    "    natural_distances_source_data.loc[\n",
    "        natural_distances_source_data[\"model\"] != \"naive\",\n",
    "        tuple(distances_source_file_columns.keys())\n",
    "    ].copy().rename(columns=distances_source_file_columns),\n",
    "    3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "natural_distances_source_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "natural_distances_source_data.to_csv(\n",
    "    source_data_for_natural_model_distances,\n",
    "    header=True,\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Inspection of epitope cross-immunity performance\n",
    "\n",
    "Epitope cross-immunity has strong predictive support in training data, based on its consistently high coefficient prior to October 2009."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_of_natural_validation_coefficients_by_time_df.query(\"predictors == 'ep_x' & validation_timepoint < '2009-10-01'\")[\"coefficient\"].aggregate([\"mean\", \"std\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By the validation timepoint for October 2009, the training data for the model no longer contains more pre-2006 information than 2006 and after information. At this timepoint and after the mean coefficient drops to effectively zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_of_natural_validation_coefficients_by_time_df.query(\"predictors == 'ep_x' & validation_timepoint >= '2009-10-01'\")[\"coefficient\"].aggregate([\"mean\", \"std\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epitope cross-immunity does not overfit for the first few validation timepoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_of_natural_validation_errors_by_time_df.query(\"predictors == 'ep_x'\").loc[\n",
    "    :, [\"validation_timepoint\", \"validation_error\", \"null_validation_error\"]\n",
    "].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Individual models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "natural_errors_by_time_df.query(\"predictors == 'dms_star' & model_improvement > 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure S6. Comparison of models based on epitope sites\n",
    "\n",
    "Original epitope sites from Luksza and Lassig 2014 (`ep_x` or \"epitope antigenic novelty\") compared to comparable sites from a reanalysis of mutational sweeps up through 2015 (`oracle_x` or \"oracle antigenic novelty\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes, gs = plot_model_accuracy_and_coefficients_for_build(\n",
    "    natural_errors_by_time_df,\n",
    "    natural_coefficients_by_time_df,\n",
    "    [\"ep_x\", \"oracle_x\"],\n",
    "    height=5,\n",
    "    rotation=0,\n",
    "    max_normal_error=12\n",
    ")\n",
    "\n",
    "plt.figtext(0.0, 0.96, \"A\", **panel_labels_dict)\n",
    "plt.figtext(0.49, 0.96, \"B\", **panel_labels_dict)\n",
    "\n",
    "plt.savefig(figure_for_natural_epitope_vs_oracle_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 5. Natural model results for individual predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes, gs = plot_model_accuracy_and_coefficients_for_build(\n",
    "    natural_errors_by_time_df,\n",
    "    natural_coefficients_by_time_df,\n",
    "    subset_of_individual_predictors,\n",
    "    height=10,\n",
    "    rotation=0,\n",
    "    max_normal_error=17,\n",
    "    distance_tick_multiple=3\n",
    ")\n",
    "\n",
    "plt.figtext(0.0, 0.98, \"A\", **panel_labels_dict)\n",
    "plt.figtext(0.49, 0.98, \"B\", **panel_labels_dict)\n",
    "\n",
    "plt.savefig(figure_for_natural_individual_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "natural_errors_by_time_df[\n",
    "    (natural_errors_by_time_df[\"validation_timepoint\"] == \"2014-10-01\") & (natural_errors_by_time_df[\"predictors\"] == \"lbi\")\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 6. Natural model results for composite predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes, gs = plot_model_accuracy_and_coefficients_for_build(\n",
    "    natural_errors_by_time_df,\n",
    "    natural_coefficients_by_time_df,\n",
    "    composite_models,\n",
    "    height=7,\n",
    "    text_vertical_padding=0.12,\n",
    "    rotation=0,\n",
    "    max_normal_error=17,\n",
    "    distance_tick_multiple=3\n",
    ")\n",
    "\n",
    "plt.figtext(0.0, 0.96, \"A\", **panel_labels_dict)\n",
    "plt.figtext(0.49, 0.96, \"B\", **panel_labels_dict)\n",
    "\n",
    "plt.savefig(figure_for_natural_composite_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate sum of differences between the estimated distances from the naive model and each biological model. The higher sum per model, the more the biological model outperforms the naive model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_error_df = errors_by_time_df[errors_by_time_df[\"predictors\"] == \"naive\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "natural_errors_by_time_with_naive_df = natural_errors_by_time_df.merge(\n",
    "    naive_error_df,\n",
    "    on=[\"validation_timepoint\", \"validation_n\", \"type\", \"sample\"],\n",
    "    suffixes=[\"_model\", \"_naive\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "natural_errors_by_time_with_naive_df[\"model_gain\"] = (\n",
    "    natural_errors_by_time_with_naive_df[\"validation_error_naive\"] - natural_errors_by_time_with_naive_df[\"validation_error_model\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "natural_errors_by_time_with_naive_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "natural_errors_by_time_with_naive_df.groupby(\"predictors_model\")[\"model_gain\"].sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cross_validation_times(data, ax, years_fmt_string):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    timepoints = data.loc[:, [\"validation_timepoint\", \"error_type\"]].drop_duplicates()\n",
    "    y_positions = list(range(len(timepoints.values)))\n",
    "    \n",
    "    validation_timepoints = timepoints.query(\"error_type == 'validation'\").loc[:, \"validation_timepoint\"].apply(\n",
    "        lambda time: time.toordinal()\n",
    "    ).values\n",
    "    validation_y_positions = y_positions[:len(validation_timepoints)]\n",
    "\n",
    "    test_timepoints = timepoints.query(\"error_type == 'test'\").loc[:, \"validation_timepoint\"].apply(\n",
    "        lambda time: time.toordinal()\n",
    "    ).values\n",
    "    test_y_positions = y_positions[len(validation_timepoints):]\n",
    "    \n",
    "    one_year = pd.DateOffset(years=1)\n",
    "    training_window = pd.DateOffset(years=6)\n",
    "    \n",
    "    training_line_segments = [\n",
    "        [((timepoint - one_year - training_window).toordinal(), y), ((timepoint - one_year).toordinal(), y)]\n",
    "        for timepoint, y in zip(timepoints.query(\"error_type == 'validation'\").loc[:, \"validation_timepoint\"], validation_y_positions)\n",
    "    ]\n",
    "\n",
    "    markersize = 4\n",
    "    years = mdates.YearLocator(5)\n",
    "    years_fmt = mdates.DateFormatter(years_fmt_string)\n",
    "    months = mdates.MonthLocator()\n",
    "\n",
    "    training_lc = LineCollection(training_line_segments, zorder=9)\n",
    "    training_lc.set_color(\"#999999\")\n",
    "    training_lc.set_linewidth(1)\n",
    "    training_lc.set_label(\"Training\")\n",
    "    training_artist = ax.add_collection(training_lc)\n",
    "\n",
    "    validation_artist, = ax.plot(\n",
    "        validation_timepoints,\n",
    "        validation_y_positions,\n",
    "        \"o\",\n",
    "        label=\"Validation\",\n",
    "        markersize=markersize,\n",
    "        color=\"#000000\"\n",
    "    )\n",
    "    test_artist, = ax.plot(\n",
    "        test_timepoints,\n",
    "        test_y_positions,\n",
    "        \"o\",\n",
    "        label=\"Test\",\n",
    "        markersize=markersize,\n",
    "        color=\"#000000\",\n",
    "        fillstyle=\"none\"\n",
    "    )\n",
    "\n",
    "    ax.xaxis.set_major_locator(years)\n",
    "    ax.xaxis.set_major_formatter(years_fmt)\n",
    "    ax.xaxis.set_minor_locator(months)\n",
    "    ax.format_xdata = mdates.DateFormatter(\"%y-%m\")\n",
    "\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.tick_params(axis='y',size=0)\n",
    "    ax.set_yticklabels([])\n",
    "\n",
    "    handles = [training_artist, validation_artist]\n",
    "    labels = [\"Training\", \"Validation\"]\n",
    "    \n",
    "    if len(test_timepoints) > 0:\n",
    "        handles.append(test_artist)\n",
    "        labels.append(\"Test\")\n",
    "    \n",
    "    ax.legend(\n",
    "        handles,\n",
    "        labels,\n",
    "        frameon=False\n",
    "    )\n",
    "    \n",
    "    ax.set_xlabel(\"Date\")\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure S1. Cross-validation of simulated populations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(8, 4))\n",
    "ax = plot_cross_validation_times(simulated_errors_by_time_df, ax, years_fmt_string=\"%y\")\n",
    "fig.autofmt_xdate(rotation=0, ha=\"center\")\n",
    "\n",
    "plt.savefig(figure_for_simulated_cross_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure S5. Cross-validation of simulated populations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(8, 4))\n",
    "ax = plot_cross_validation_times(natural_errors_by_time_df, ax, years_fmt_string=\"%Y\")\n",
    "fig.autofmt_xdate(rotation=0, ha=\"center\")\n",
    "\n",
    "plt.savefig(figure_for_natural_cross_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure S8. Natural model coefficients and distances refit across test timepoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_natural_sample = \"natural_sample_20191001\"\n",
    "latest_natural_errors_by_time_df = errors_by_time_df[errors_by_time_df[\"sample\"] == latest_natural_sample].copy()\n",
    "latest_natural_coefficients_by_time_df = coefficients_by_time_df[coefficients_by_time_df[\"sample\"] == latest_natural_sample].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes, gs = plot_model_accuracy_and_coefficients_for_build(\n",
    "    latest_natural_errors_by_time_df,\n",
    "    latest_natural_coefficients_by_time_df,\n",
    "    [\"cTiter_x-ne_star\", \"fra_cTiter_x-ne_star\", \"ne_star-lbi\", \"cTiter_x-ne_star-lbi\"],\n",
    "    rotation=0,\n",
    "    years_fmt_string=\"%Y\",\n",
    "    date_fmt_string=\"%Y-%m\",\n",
    "    height=8,\n",
    "    hspace=0.1,\n",
    "    share_y=True,\n",
    "    max_coefficient=7,\n",
    "    max_normal_error=19,\n",
    "    distance_tick_multiple=3\n",
    ")\n",
    "\n",
    "plt.figtext(0.0, 0.97, \"A\", **panel_labels_dict)\n",
    "plt.figtext(0.49, 0.97, \"B\", **panel_labels_dict)\n",
    "\n",
    "plt.savefig(figure_for_natural_updated_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_natural_errors_by_time_df.query(\"predictors == 'naive'\")[\"validation_error\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_natural_errors_by_time_df.query(\"predictors == 'naive'\")[\"validation_error\"].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_natural_errors_by_time_df.query(\"predictors == 'naive'\")[\"optimal_validation_error\"].aggregate([\n",
    "    \"mean\",\n",
    "    \"std\"\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Investigate distances to the future by Hemisphere\n",
    "\n",
    "Plot the distributions of distances to the future by Hemisphere for the best model.\n",
    "We make Northern Hemisphere predictions in October and Southern Hemisphere predictions in April."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "natural_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_natural_model = \"cTiter_x-ne_star\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_natural_model_df = errors_by_time_df.query(\n",
    "    f\"(sample == '{natural_sample}') & (predictors == '{best_natural_model}')\"\n",
    ").copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "Annotate forecast hemispheres by the month when the forecast was made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_natural_model_df[\"hemisphere\"] = best_natural_model_df[\"validation_timepoint\"].dt.month.apply(\n",
    "    lambda month: \"Northern\" if month == 10 else \"Southern\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "Investigate absolute distance to the future measured by the best model for natural populations. These distances do not account for seasonal variation in observed distance to the future that is measured by the naive model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.violinplot(\n",
    "    x=\"hemisphere\",\n",
    "    y=\"validation_error\",\n",
    "    data=best_natural_model_df,\n",
    "    inner=None\n",
    ")\n",
    "ax = sns.swarmplot(\n",
    "    x=\"hemisphere\",\n",
    "    y=\"validation_error\",\n",
    "    data=best_natural_model_df,\n",
    "    ax=ax,\n",
    "    color=\"black\"\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"Hemisphere\")\n",
    "ax.set_ylabel(\"Distance to the future (AAs)\\nfor HI + mutational load\")\n",
    "ax.set_ylim(bottom=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "Investigate adjusted distance to the future for the best model where seasonal variation measured by the naive model is accounted for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.violinplot(\n",
    "    x=\"hemisphere\",\n",
    "    y=\"model_improvement\",\n",
    "    data=best_natural_model_df,\n",
    "    inner=None\n",
    ")\n",
    "ax = sns.swarmplot(\n",
    "    x=\"hemisphere\",\n",
    "    y=\"model_improvement\",\n",
    "    data=best_natural_model_df,\n",
    "    ax=ax,\n",
    "    color=\"black\"\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"Hemisphere\")\n",
    "ax.set_ylabel(\"Naive - model\\ndistance to the future (AAs)\")\n",
    "#ax.set_ylim(bottom=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "Inspect the median adjusted distance to the future by hemisphere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_natural_model_df.groupby(\"hemisphere\")[\"model_improvement\"].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "Count the number of timepoints in each hemisphere group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_natural_model_df.groupby(\"hemisphere\")[\"model_improvement\"].count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
