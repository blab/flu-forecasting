{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrap distances to the future\n",
    "\n",
    "Estimate uncertainty of distance to the future values per sample and model using the bootstrap of differences between observed distances across time for biologically-informed and naive models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define inputs, outputs, and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define inputs.\n",
    "model_distances = snakemake.input.model_distances\n",
    "\n",
    "# Define outputs.\n",
    "output_table = snakemake.output.output_table\n",
    "bootstrap_figure_for_simulated_sample = snakemake.output.bootstrap_figure_for_simulated_sample\n",
    "bootstrap_figure_for_natural_sample = snakemake.output.bootstrap_figure_for_natural_sample\n",
    "composite_vs_individual_model_table = snakemake.output.composite_vs_individual_model_table\n",
    "\n",
    "# Define parameters.\n",
    "n_bootstraps = snakemake.params.n_bootstraps\n",
    "\n",
    "error_types = [\"validation\", \"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Configure plots and analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display figures at a reasonable default size.\n",
    "mpl.rcParams['figure.figsize'] = (6, 4)\n",
    "\n",
    "# Disable top and right spines.\n",
    "mpl.rcParams['axes.spines.top'] = False\n",
    "mpl.rcParams['axes.spines.right'] = False\n",
    "    \n",
    "# Display and save figures at higher resolution for presentations and manuscripts.\n",
    "mpl.rcParams['savefig.dpi'] = 200\n",
    "mpl.rcParams['figure.dpi'] = 120\n",
    "\n",
    "# Display text at sizes large enough for presentations and manuscripts.\n",
    "mpl.rcParams['font.weight'] = \"normal\"\n",
    "mpl.rcParams['axes.labelweight'] = \"normal\"\n",
    "mpl.rcParams['font.size'] = 14\n",
    "mpl.rcParams['axes.labelsize'] = 14\n",
    "mpl.rcParams['legend.fontsize'] = 12\n",
    "mpl.rcParams['xtick.labelsize'] = 12\n",
    "mpl.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "mpl.rc('text', usetex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_by_predictor = {\n",
    "    'naive': '#cccccc',\n",
    "    'offspring': '#000000',\n",
    "    'normalized_fitness': '#999999',\n",
    "    'fitness': '#000000',\n",
    "    'ep': '#4575b4',\n",
    "    'ep_wolf': '#4575b4',\n",
    "    'ep_star': '#4575b4',\n",
    "    'ep_x': '#4575b4',\n",
    "    'ep_x_koel': '#4575b4',\n",
    "    'ep_x_wolf': '#4575b4',\n",
    "    'oracle_x': '#4575b4',\n",
    "    'rb': '#4575b4',\n",
    "    'cTiter': '#91bfdb',\n",
    "    'cTiter_x': '#91bfdb',\n",
    "    'cTiterSub': '#91bfdb',\n",
    "    'cTiterSub_star': '#91bfdb',\n",
    "    'cTiterSub_x': '#91bfdb',\n",
    "    'fra_cTiter_x': '#91bfdb',\n",
    "    'ne_star': '#2ca25f',\n",
    "    'dms_star': '#99d8c9',\n",
    "    \"dms_nonepitope\": \"#99d8c9\",\n",
    "    \"dms_entropy\": \"#99d8c9\",\n",
    "    'unnormalized_lbi': '#fc8d59',\n",
    "    'lbi': '#fc8d59',\n",
    "    'delta_frequency': '#d73027',\n",
    "    'ep_x-ne_star': \"#ffffff\",\n",
    "    'ep_star-ne_star': \"#ffffff\",\n",
    "    'lbi-ne_star': \"#ffffff\",\n",
    "    'ne_star-lbi': \"#ffffff\",\n",
    "    'cTiter_x-ne_star': \"#ffffff\",\n",
    "    'cTiter_x-ne_star-lbi': \"#ffffff\",\n",
    "    'fra_cTiter_x-ne_star': \"#ffffff\"\n",
    "}\n",
    "\n",
    "name_by_predictor = {\n",
    "    \"naive\": \"naive\",\n",
    "    \"offspring\": \"observed fitness\",\n",
    "    \"normalized_fitness\": \"true fitness\",\n",
    "    \"fitness\": \"estimated fitness\",\n",
    "    \"ep\": \"epitope mutations\",\n",
    "    \"ep_wolf\": \"Wolf epitope mutations\",\n",
    "    \"ep_star\": \"epitope ancestor\",\n",
    "    \"ep_x\": \"epitope antigenic\\nnovelty\",\n",
    "    \"ep_x_koel\": \"Koel epitope antigenic novelty\",\n",
    "    \"ep_x_wolf\": \"Wolf epitope antigenic novelty\",\n",
    "    \"oracle_x\": \"oracle antigenic novelty\",\n",
    "    \"rb\": \"Koel epitope mutations\",\n",
    "    \"cTiter\": \"antigenic advance\",\n",
    "    \"cTiter_x\": \"HI antigenic novelty\",\n",
    "    \"cTiterSub\": \"linear HI mut phenotypes\",\n",
    "    \"cTiterSub_star\": \"ancestral HI mut phenotypes\",\n",
    "    \"cTiterSub_x\": \"HI sub cross-immunity\",\n",
    "    \"fra_cTiter_x\": \"FRA antigenic novelty\",\n",
    "    \"ne_star\": \"mutational load\",\n",
    "    \"dms_star\": \"DMS mutational\\neffects\",\n",
    "    \"dms_nonepitope\": \"DMS mutational load\",\n",
    "    \"dms_entropy\": \"DMS entropy\",\n",
    "    \"unnormalized_lbi\": \"unnormalized LBI\",\n",
    "    \"lbi\": \"LBI\",\n",
    "    \"delta_frequency\": \"delta frequency\",\n",
    "    'ep_x-ne_star': \"mutational load +\\nepitope antigenic\\nnovelty\",\n",
    "    'ep_star-ne_star': \"mutational load +\\nepitope ancestor\",\n",
    "    'lbi-ne_star': \"mutational load +\\n LBI\",\n",
    "    'ne_star-lbi': \"mutational load +\\n LBI\",\n",
    "    'cTiter_x-ne_star': \"mutational load +\\nHI antigenic novelty\",\n",
    "    'cTiter_x-ne_star-lbi': \"mutational load +\\nHI antigenic novelty +\\nLBI\",\n",
    "    'fra_cTiter_x-ne_star': \"mutational load +\\nFRA antigenic novelty\"\n",
    "}\n",
    "\n",
    "name_by_sample = {\n",
    "    \"simulated_sample_3\": \"simulated populations\",\n",
    "    \"natural_sample_1_with_90_vpm_sliding\": \"natural populations\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_by_model = {name_by_predictor[predictor]: color for predictor, color in color_by_predictor.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors_by_sample = {\n",
    "    \"simulated_sample_3\": [\n",
    "        \"normalized_fitness\",\n",
    "        \"ep_star\",\n",
    "        \"ep_x\",\n",
    "        \"ne_star\",\n",
    "        \"lbi\",\n",
    "        \"delta_frequency\",\n",
    "        \"ep_star-ne_star\",\n",
    "        \"ep_x-ne_star\",\n",
    "        \"lbi-ne_star\"\n",
    "    ],\n",
    "    \"natural_sample_1_with_90_vpm_sliding\": [\n",
    "        \"ep_x\",\n",
    "        \"cTiter_x\",\n",
    "        \"ne_star\",\n",
    "        \"dms_star\",\n",
    "        \"lbi\",\n",
    "        \"delta_frequency\",\n",
    "        \"ep_star-ne_star\",\n",
    "        \"ep_x-ne_star\",\n",
    "        \"cTiter_x-ne_star\",\n",
    "        \"ne_star-lbi\",\n",
    "        \"cTiter_x-ne_star-lbi\"\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_table(model_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_distances_by_build(df, sample, error_type, predictors):\n",
    "    return df.query(\n",
    "        f\"(sample == '{sample}') & (error_type == '{error_type}') & (predictors == '{predictors}')\"\n",
    "    )[\"validation_error\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate bootstraps for all models and samples\n",
    "\n",
    "Build bootstrap distributions for empirical differences between biologically-informed and naive models at each timepoint. Values that are less than zero occur when a given model estimates a population closer to the future than the naive model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"error_difference\"] = df[\"validation_error\"] - df[\"null_validation_error\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"sample\", \"error_type\", \"predictors\"])[\"error_difference\"].aggregate([\"mean\", \"std\"]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_distances = []\n",
    "for (sample, error_type, predictors), group_df in df.groupby([\"sample\", \"error_type\", \"predictors\"]):\n",
    "    if sample not in predictors_by_sample:\n",
    "        continue\n",
    "        \n",
    "    if predictors not in predictors_by_sample[sample]:\n",
    "        continue\n",
    "        \n",
    "    print(f\"Processing: {sample}, {error_type}, {predictors}\")\n",
    "    \n",
    "    # Calculate difference between validation error\n",
    "    \n",
    "    bootstrap_distribution = [\n",
    "        group_df[\"error_difference\"].sample(frac=1.0, replace=True).mean()\n",
    "        for i in range(n_bootstraps)\n",
    "    ]\n",
    "    \n",
    "    bootstrap_distances.append(pd.DataFrame({\n",
    "        \"sample\": sample,\n",
    "        \"error_type\": error_type,\n",
    "        \"predictors\": predictors,\n",
    "        \"bootstrap_distance\": bootstrap_distribution\n",
    "    }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstraps_df = pd.concat(bootstrap_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstraps_df[\"model\"] = bootstraps_df[\"predictors\"].map(name_by_predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstraps_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstraps_df.groupby([\"sample\", \"error_type\", \"predictors\"])[\"bootstrap_distance\"].aggregate([\n",
    "    \"mean\",\n",
    "    \"std\"\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate p values from bootstraps\n",
    "\n",
    "Estimate signifance of difference between each model's distance to the future and the corresponding naive model by calculating the proportion of bootstraps with values less than zero. The null hypothesis here is that there is no difference between biologically-informed and naive models at each timepoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_bootstraps_df = bootstraps_df.groupby([\"sample\", \"error_type\", \"predictors\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_value_df = grouped_bootstraps_df.apply(\n",
    "    lambda grouped_df: sum(grouped_df[\"bootstrap_distance\"] >= 0) / float(n_bootstraps)\n",
    ").reset_index().rename(columns={0: \"p_value\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_value_df[p_value_df[\"p_value\"] < 0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_value_df.to_csv(output_table, sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot bootstrap distributions used to calculate p values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bootstrap_distances(bootstraps_df, predictors, title, width=16, height=8):\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(width, height), sharey=True)\n",
    "\n",
    "    sample_name = bootstraps_df[\"sample\"].drop_duplicates().values[0]\n",
    "    bootstrap_df = bootstraps_df.query(\"error_type == 'validation'\")\n",
    "    bootstrap_df = bootstrap_df[bootstrap_df[\"predictors\"].isin(predictors)].copy()\n",
    "\n",
    "    # Use this order for both validation and test facets as in Tables 1 and 2.\n",
    "    models_order = bootstrap_df.groupby(\"model\")[\"bootstrap_distance\"].mean().sort_values().reset_index()[\"model\"].values\n",
    "    predictors_order = bootstrap_df.groupby(\"predictors\")[\"bootstrap_distance\"].mean().sort_values().reset_index()[\"predictors\"].values\n",
    "       \n",
    "    validation_ax = axes[0]\n",
    "    validation_ax = sns.violinplot(\n",
    "        x=\"model\",\n",
    "        y=\"bootstrap_distance\",\n",
    "        data=bootstrap_df,\n",
    "        order=models_order,\n",
    "        ax=validation_ax,\n",
    "        palette=color_by_model,\n",
    "        cut=0\n",
    "    )\n",
    "    \n",
    "    max_distance = bootstrap_df[\"bootstrap_distance\"].max() + 0.1\n",
    "    validation_ax.set_ylim(top=max_distance + 0.75)\n",
    "    \n",
    "    for index, predictor in enumerate(predictors_order):\n",
    "        if predictor == \"naive\":\n",
    "            continue\n",
    "            \n",
    "        p_value = p_value_df.query(f\"(sample == '{sample_name}') & (error_type == 'validation') & (predictors == '{predictor}')\")[\"p_value\"].values[0]\n",
    "        if p_value < (1.0 / n_bootstraps):\n",
    "            p_value_string = f\"p < {1.0 / n_bootstraps}\"\n",
    "        else:\n",
    "            p_value_string = f\"p = {p_value:.4f}\"\n",
    "\n",
    "        differences = bootstrap_df.query(f\"(predictors == '{predictor}')\")[\"bootstrap_distance\"]\n",
    "        mean_difference = differences.mean()\n",
    "        std_difference = differences.std()\n",
    "        \n",
    "        effect_description = f\"{mean_difference:.2f} +/- {std_difference:.2f} AAs\\n{p_value_string}\"\n",
    "            \n",
    "        validation_ax.text(\n",
    "            index,\n",
    "            max_distance,\n",
    "            effect_description,\n",
    "            fontsize=12,\n",
    "            horizontalalignment=\"center\",\n",
    "            verticalalignment=\"bottom\"\n",
    "        )\n",
    "\n",
    "    validation_ax.axhline(y=0.0, label=\"naive\", color=\"#999999\", zorder=-10)\n",
    "    validation_ax.title.set_text(f\"Validation of {name_by_sample[sample]}\")\n",
    "\n",
    "    validation_ax.set_xlabel(\"Model\")\n",
    "    validation_ax.set_ylabel(\"Bootstrapped model - naive\\ndistance to future (AAs)\")\n",
    "\n",
    "    bootstrap_df = bootstraps_df.query(\"error_type == 'test'\")\n",
    "    bootstrap_df = bootstrap_df[bootstrap_df[\"predictors\"].isin(predictors)].copy()\n",
    "\n",
    "    test_ax = axes[1]\n",
    "    test_ax = sns.violinplot(\n",
    "        x=\"model\",\n",
    "        y=\"bootstrap_distance\",\n",
    "        data=bootstrap_df,\n",
    "        order=models_order,\n",
    "        ax=test_ax,\n",
    "        palette=color_by_model,\n",
    "        cut=0\n",
    "    )\n",
    "\n",
    "    max_distance = bootstrap_df[\"bootstrap_distance\"].max() + 0.1\n",
    "    test_ax.set_ylim(top=max_distance + 0.75)\n",
    "    \n",
    "    for index, predictor in enumerate(predictors_order):\n",
    "        if predictor == \"naive\":\n",
    "            continue\n",
    "            \n",
    "        p_value = p_value_df.query(f\"(sample == '{sample_name}') & (error_type == 'test') & (predictors == '{predictor}')\")[\"p_value\"].values[0]\n",
    "        if p_value < (1.0 / n_bootstraps):\n",
    "            p_value_string = f\"p < {1.0 / n_bootstraps}\"\n",
    "        else:\n",
    "            p_value_string = f\"p = {p_value:.4f}\"\n",
    "\n",
    "        differences = bootstrap_df.query(f\"(predictors == '{predictor}')\")[\"bootstrap_distance\"]\n",
    "        mean_difference = differences.mean()\n",
    "        std_difference = differences.std()\n",
    "        \n",
    "        effect_description = f\"{mean_difference:.2f} +/- {std_difference:.2f} AAs\\n{p_value_string}\"\n",
    "\n",
    "        test_ax.text(\n",
    "            index,\n",
    "            max_distance,\n",
    "            effect_description,\n",
    "            fontsize=12,\n",
    "            horizontalalignment=\"center\",\n",
    "            verticalalignment=\"bottom\"\n",
    "        )\n",
    "\n",
    "    test_ax.set_xlabel(\"Model\")\n",
    "    test_ax.set_ylabel(\"Bootstrapped model - naive\\ndistance to future (AAs)\")\n",
    "\n",
    "    test_ax.axhline(y=0.0, label=\"no difference from naive\", color=\"#999999\", zorder=-10)\n",
    "    test_ax.title.set_text(f\"Test of {name_by_sample[sample]}\")\n",
    "\n",
    "    sns.despine()\n",
    "    \n",
    "    fig.tight_layout(pad=0.75, w_pad=1.0, h_pad=1.0)\n",
    "    \n",
    "    return fig, axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = \"simulated_sample_3\"\n",
    "fig, axes = plot_bootstrap_distances(\n",
    "    bootstraps_df.query(f\"sample == '{sample}'\"),\n",
    "    predictors_by_sample[sample],\n",
    "    name_by_sample[sample],\n",
    "    width=16\n",
    ")\n",
    "\n",
    "plt.savefig(bootstrap_figure_for_simulated_sample, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = \"natural_sample_1_with_90_vpm_sliding\"\n",
    "fig, axes = plot_bootstrap_distances(\n",
    "    bootstraps_df.query(f\"sample == '{sample}'\"),\n",
    "    predictors_by_sample[sample],\n",
    "    name_by_sample[sample],\n",
    "    width=20,\n",
    "    height=10\n",
    ")\n",
    "\n",
    "plt.savefig(bootstrap_figure_for_natural_sample, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compare distributions of composite and individual models\n",
    "\n",
    "Perform bootstrap tests between composite models and their respective individual models to determine whether any composite models are significantly more accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "composite_models = {\n",
    "    \"simulated_sample_3\": [\n",
    "        {\n",
    "            \"individual\": [\"ne_star\", \"lbi\", \"normalized_fitness\"],\n",
    "            \"composite\": \"lbi-ne_star\"\n",
    "        }\n",
    "    ],\n",
    "    \"natural_sample_1_with_90_vpm_sliding\": [\n",
    "        {\n",
    "            \"individual\": [\"cTiter_x\", \"ne_star\"],\n",
    "            \"composite\": \"cTiter_x-ne_star\"\n",
    "        },\n",
    "        {\n",
    "            \"individual\": [\"ne_star\", \"lbi\"],\n",
    "            \"composite\": \"ne_star-lbi\"\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "composite_vs_individual_p_values = []\n",
    "\n",
    "for error_type in error_types:\n",
    "    for sample, models in composite_models.items():\n",
    "        for model in models:\n",
    "            composite_dist = get_model_distances_by_build(df, sample, error_type, model[\"composite\"])\n",
    "\n",
    "            for individual_model in model[\"individual\"]:\n",
    "                individual_dist = get_model_distances_by_build(df, sample, error_type, individual_model)\n",
    "\n",
    "                # Calculate the difference between the composite model's distance to the future\n",
    "                # and the individual model's at the same timepoint. This difference should\n",
    "                # account for timepoint-to-timepoint variation observed across all models.\n",
    "                difference_dist = pd.Series(composite_dist - individual_dist)\n",
    "                \n",
    "                bootstrap_distribution = np.array([\n",
    "                    difference_dist.sample(frac=1.0, replace=True).mean()\n",
    "                    for i in range(n_bootstraps)\n",
    "                ])\n",
    "                p_value = (bootstrap_distribution >= 0).sum() / float(n_bootstraps)\n",
    "\n",
    "                composite_vs_individual_p_values.append({\n",
    "                    \"sample\": sample,\n",
    "                    \"error_type\": error_type,\n",
    "                    \"individual_model\": individual_model,\n",
    "                    \"composite_model\": model[\"composite\"],\n",
    "                    \"bootstrap_mean\": bootstrap_distribution.mean(),\n",
    "                    \"bootstrap_std\": bootstrap_distribution.std(),\n",
    "                    \"p_value\": p_value\n",
    "                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "composite_vs_individual_p_values_df = pd.DataFrame(composite_vs_individual_p_values).sort_values(\n",
    "    [\"sample\", \"error_type\", \"composite_model\", \"individual_model\"],\n",
    "    ascending=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "composite_vs_individual_p_values_df[\"individual_model\"] = composite_vs_individual_p_values_df[\"individual_model\"].map(\n",
    "    name_by_predictor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "composite_vs_individual_p_values_df[\"composite_model\"] = composite_vs_individual_p_values_df[\"composite_model\"].map(\n",
    "    name_by_predictor\n",
    ").apply(lambda name: name.replace(\"\\n\", \" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "composite_vs_individual_p_values_df[\"sample\"] = composite_vs_individual_p_values_df[\"sample\"].map(\n",
    "    name_by_sample\n",
    ").apply(lambda name: name.replace(\" populations\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "composite_vs_individual_p_values_df[\"bootstrap_mean\"] = np.around(\n",
    "    composite_vs_individual_p_values_df[\"bootstrap_mean\"],\n",
    "    2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "composite_vs_individual_p_values_df[\"bootstrap_std\"] = np.around(\n",
    "    composite_vs_individual_p_values_df[\"bootstrap_std\"],\n",
    "    2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "composite_vs_individual_p_values_df[\"p_value\"] = composite_vs_individual_p_values_df[\"p_value\"].apply(\n",
    "    lambda p_value: f\"$<${1.0 / n_bootstraps}\" if p_value == 0.0 else str(p_value)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "composite_vs_individual_p_values_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(composite_vs_individual_p_values_df.to_latex().replace(\"\\$\", \"$\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(composite_vs_individual_model_table, \"w\") as oh:\n",
    "    oh.write(composite_vs_individual_p_values_df.to_latex(index=False).replace(\"\\$\", \"$\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
