{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bootstrap distances to the future\n",
    "\n",
    "Estimate uncertainty of distance to the future values per sample and model using the bootstrap of observed distances across time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define inputs, outputs, and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define inputs.\n",
    "model_distances = snakemake.input.model_distances\n",
    "\n",
    "# Define outputs.\n",
    "output_table = snakemake.output.output_table\n",
    "bootstrap_figure_for_simulated_sample = snakemake.output.bootstrap_figure_for_simulated_sample\n",
    "bootstrap_figure_for_natural_sample = snakemake.output.bootstrap_figure_for_natural_sample\n",
    "\n",
    "# Define parameters.\n",
    "n_bootstraps = snakemake.params.n_bootstraps\n",
    "\n",
    "error_types = [\"validation\", \"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure plots and analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display figures at a reasonable default size.\n",
    "mpl.rcParams['figure.figsize'] = (6, 4)\n",
    "\n",
    "# Disable top and right spines.\n",
    "mpl.rcParams['axes.spines.top'] = False\n",
    "mpl.rcParams['axes.spines.right'] = False\n",
    "    \n",
    "# Display and save figures at higher resolution for presentations and manuscripts.\n",
    "mpl.rcParams['savefig.dpi'] = 200\n",
    "mpl.rcParams['figure.dpi'] = 120\n",
    "\n",
    "# Display text at sizes large enough for presentations and manuscripts.\n",
    "mpl.rcParams['font.weight'] = \"normal\"\n",
    "mpl.rcParams['axes.labelweight'] = \"normal\"\n",
    "mpl.rcParams['font.size'] = 14\n",
    "mpl.rcParams['axes.labelsize'] = 14\n",
    "mpl.rcParams['legend.fontsize'] = 12\n",
    "mpl.rcParams['xtick.labelsize'] = 12\n",
    "mpl.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "mpl.rc('text', usetex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_by_predictor = {\n",
    "    'naive': '#cccccc',\n",
    "    'offspring': '#000000',\n",
    "    'normalized_fitness': '#999999',\n",
    "    'fitness': '#000000',\n",
    "    'ep': '#4575b4',\n",
    "    'ep_wolf': '#4575b4',\n",
    "    'ep_star': '#4575b4',\n",
    "    'ep_x': '#4575b4',\n",
    "    'ep_x_koel': '#4575b4',\n",
    "    'ep_x_wolf': '#4575b4',\n",
    "    'oracle_x': '#4575b4',\n",
    "    'rb': '#4575b4',\n",
    "    'cTiter': '#91bfdb',\n",
    "    'cTiter_x': '#91bfdb',\n",
    "    'cTiterSub': '#91bfdb',\n",
    "    'cTiterSub_star': '#91bfdb',\n",
    "    'cTiterSub_x': '#91bfdb',\n",
    "    'fra_cTiter_x': '#91bfdb',\n",
    "    'ne_star': '#2ca25f',\n",
    "    'dms_star': '#99d8c9',\n",
    "    \"dms_nonepitope\": \"#99d8c9\",\n",
    "    \"dms_entropy\": \"#99d8c9\",\n",
    "    'unnormalized_lbi': '#fc8d59',\n",
    "    'lbi': '#fc8d59',\n",
    "    'delta_frequency': '#d73027',\n",
    "    'ep_x-ne_star': \"#ffffff\",\n",
    "    'ep_star-ne_star': \"#ffffff\",\n",
    "    'lbi-ne_star': \"#ffffff\",\n",
    "    'ne_star-lbi': \"#ffffff\",\n",
    "    'cTiter_x-ne_star': \"#ffffff\",\n",
    "    'cTiter_x-ne_star-lbi': \"#ffffff\",\n",
    "    'fra_cTiter_x-ne_star': \"#ffffff\"\n",
    "}\n",
    "\n",
    "histogram_color_by_predictor = {\n",
    "    'naive': '#cccccc',\n",
    "    'offspring': '#000000',\n",
    "    'normalized_fitness': '#000000',\n",
    "    'fitness': '#000000',\n",
    "    'ep': '#4575b4',\n",
    "    'ep_wolf': '#4575b4',\n",
    "    'ep_star': '#4575b4',\n",
    "    'ep_x': '#4575b4',\n",
    "    'ep_x_koel': '#4575b4',\n",
    "    'ep_x_wolf': '#4575b4',\n",
    "    'oracle_x': '#4575b4',\n",
    "    'rb': '#4575b4',\n",
    "    'cTiter': '#91bfdb',\n",
    "    'cTiter_x': '#91bfdb',\n",
    "    'cTiterSub': '#91bfdb',\n",
    "    'cTiterSub_star': '#91bfdb',\n",
    "    'cTiterSub_x': '#91bfdb',\n",
    "    'fra_cTiter_x': '#91bfdb',\n",
    "    'ne_star': '#2ca25f',\n",
    "    'dms_star': '#99d8c9',\n",
    "    \"dms_nonepitope\": \"#99d8c9\",\n",
    "    \"dms_entropy\": \"#99d8c9\",\n",
    "    'unnormalized_lbi': '#fc8d59',\n",
    "    'lbi': '#fc8d59',\n",
    "    'delta_frequency': '#d73027',\n",
    "    'ep_x-ne_star': \"#999999\",\n",
    "    'ep_star-ne_star': \"#999999\",\n",
    "    'lbi-ne_star': \"#999999\",\n",
    "    'ne_star-lbi': \"#999999\",\n",
    "    'cTiter_x-ne_star': \"#999999\",\n",
    "    'cTiter_x-ne_star-lbi': \"#999999\",\n",
    "    'fra_cTiter_x-ne_star': \"#999999\"\n",
    "}\n",
    "\n",
    "name_by_predictor = {\n",
    "    \"naive\": \"naive\",\n",
    "    \"offspring\": \"observed fitness\",\n",
    "    \"normalized_fitness\": \"true fitness\",\n",
    "    \"fitness\": \"estimated fitness\",\n",
    "    \"ep\": \"epitope mutations\",\n",
    "    \"ep_wolf\": \"Wolf epitope mutations\",\n",
    "    \"ep_star\": \"epitope ancestor\",\n",
    "    \"ep_x\": \"epitope antigenic\\nnovelty\",\n",
    "    \"ep_x_koel\": \"Koel epitope antigenic novelty\",\n",
    "    \"ep_x_wolf\": \"Wolf epitope antigenic novelty\",\n",
    "    \"oracle_x\": \"oracle antigenic novelty\",\n",
    "    \"rb\": \"Koel epitope mutations\",\n",
    "    \"cTiter\": \"antigenic advance\",\n",
    "    \"cTiter_x\": \"HI antigenic novelty\",\n",
    "    \"cTiterSub\": \"linear HI mut phenotypes\",\n",
    "    \"cTiterSub_star\": \"ancestral HI mut phenotypes\",\n",
    "    \"cTiterSub_x\": \"HI sub cross-immunity\",\n",
    "    \"fra_cTiter_x\": \"FRA antigenic novelty\",\n",
    "    \"ne_star\": \"mutational load\",\n",
    "    \"dms_star\": \"DMS mutational\\neffects\",\n",
    "    \"dms_nonepitope\": \"DMS mutational load\",\n",
    "    \"dms_entropy\": \"DMS entropy\",\n",
    "    \"unnormalized_lbi\": \"unnormalized LBI\",\n",
    "    \"lbi\": \"LBI\",\n",
    "    \"delta_frequency\": \"delta frequency\",\n",
    "    'ep_x-ne_star': \"mutational load +\\nepitope antigenic\\nnovelty\",\n",
    "    'ep_star-ne_star': \"mutational load +\\nepitope ancestor\",\n",
    "    'lbi-ne_star': \"mutational load +\\n LBI\",\n",
    "    'ne_star-lbi': \"mutational load +\\n LBI\",\n",
    "    'cTiter_x-ne_star': \"mutational load +\\nHI antigenic novelty\",\n",
    "    'cTiter_x-ne_star-lbi': \"mutational load +\\nHI antigenic novelty +\\nLBI\",\n",
    "    'fra_cTiter_x-ne_star': \"mutational load +\\nFRA antigenic novelty\"\n",
    "}\n",
    "\n",
    "name_by_sample = {\n",
    "    \"simulated_sample_3\": \"simulated populations\",\n",
    "    \"natural_sample_1_with_90_vpm_sliding\": \"natural populations\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_by_model = {name_by_predictor[predictor]: color for predictor, color in color_by_predictor.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors_by_sample = {\n",
    "    \"simulated_sample_3\": [\n",
    "        \"naive\",\n",
    "        \"normalized_fitness\",\n",
    "        \"ep_x\",\n",
    "        \"ne_star\",\n",
    "        \"lbi\",\n",
    "        \"delta_frequency\",\n",
    "        \"ep_star-ne_star\",\n",
    "        \"ep_x-ne_star\",\n",
    "        \"lbi-ne_star\"\n",
    "    ],\n",
    "    \"natural_sample_1_with_90_vpm_sliding\": [\n",
    "        \"naive\",\n",
    "        \"ep_x\",\n",
    "        \"cTiter_x\",\n",
    "        \"ne_star\",\n",
    "        \"dms_star\",\n",
    "        \"lbi\",\n",
    "        \"delta_frequency\",\n",
    "        \"ep_star-ne_star\",\n",
    "        \"ep_x-ne_star\",\n",
    "        \"cTiter_x-ne_star\",\n",
    "        \"ne_star-lbi\",\n",
    "        \"cTiter_x-ne_star-lbi\"\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_table(model_distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrap hypothesis tests\n",
    "\n",
    "Perform [bootstrap hypothesis tests](https://en.wikipedia.org/wiki/Bootstrapping_(statistics)#Bootstrap_hypothesis_testing) (Efron and Tibshirani 1993) between biologically-informed models and the naive model for each dataset.\n",
    "The following logic is copied from the article linked above to support the logic of the functions defined below.\n",
    "\n",
    "Calculate test statistic _t_:\n",
    "\n",
    "$$\n",
    "t = \\frac{\\bar{x}-\\bar{y}}{\\sqrt{\\sigma_x^2/n + \\sigma_y^2/m}}\n",
    "$$\n",
    "\n",
    "Create two new data sets whose values are $x_i^{'} = x_i - \\bar{x} + \\bar{z}$ and $y_i^{'} = y_i - \\bar{y} + \\bar{z}$, where $\\bar{z}$ is the mean of the combined sample.\n",
    "\n",
    "Draw a random sample ($x_i^*$) of size $n$ with replacement from $x_i^{'}$ and another random sample ($y_i^*$) of size $m$ with replacement from $y_i^{'}$.\n",
    "\n",
    "Calculate the test statistic $t^* = \\frac{\\bar{x^*}-\\bar{y^*}}{\\sqrt{\\sigma_x^{*2}/n + \\sigma_y^{*2}/m}}$\n",
    "\n",
    "Repeat 3 and 4 $B$ times (e.g. $B=1000$) to collect $B$ values of the test statistic.\n",
    "\n",
    "Estimate the p-value as $p = \\frac{\\sum_{i=1}^B I\\{t_i^* \\geq t\\}}{B}$ where $I(\\text{condition}) = 1$ when ''condition'' is true and 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_distances_by_build(df, sample, error_type, predictors):\n",
    "    return df.query(\n",
    "        f\"(sample == '{sample}') & (error_type == '{error_type}') & (predictors == '{predictors}')\"\n",
    "    )[\"validation_error\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_t_statistic(x_dist, y_dist):\n",
    "    \"\"\"Calculate the t statistic between two given distributions.\n",
    "    \"\"\"\n",
    "    # Calculate mean and variance for the two input distributions.\n",
    "    x_mean = x_dist.mean()\n",
    "    x_var = np.var(x_dist)\n",
    "    x_length = x_dist.shape[0]\n",
    "\n",
    "    y_mean = y_dist.mean()\n",
    "    y_var = np.var(y_dist)\n",
    "    y_length = y_dist.shape[0]\n",
    "\n",
    "    # Calculate the test statistic t.\n",
    "    t = (x_mean - y_mean) / np.sqrt((x_var / x_length) + (y_var / y_length))\n",
    "    \n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_t(x_dist_adjusted, y_dist_adjusted):\n",
    "    \"\"\"For a given pair of distributions that have been recentered on the mean of the union of their original distributions,\n",
    "    create a single bootstrap sample from each distribution and calculate the corresponding t statistic for that sample.\n",
    "    \"\"\"\n",
    "    x_dist_adjusted_sample = np.random.choice(x_dist_adjusted, size=x_dist_adjusted.shape[0], replace=True)\n",
    "    y_dist_adjusted_sample = np.random.choice(y_dist_adjusted, size=y_dist_adjusted.shape[0], replace=True)\n",
    "    \n",
    "    return calculate_t_statistic(x_dist_adjusted_sample, y_dist_adjusted_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_distributions_by_bootstrap(x_dist, y_dist, n_bootstraps):\n",
    "    \"\"\"Compare the means of two given distributions by a bootstrap hypothesis test.\n",
    "    \n",
    "    Returns the p-value, t statistic, and the bootstrap distribution of t values.\n",
    "    \"\"\"\n",
    "    # Calculate means of input distributions.\n",
    "    x_mean = x_dist.mean()\n",
    "    y_mean = y_dist.mean()\n",
    "        \n",
    "    # Calculate the test statistic t.\n",
    "    t = calculate_t_statistic(x_dist, y_dist)\n",
    "    \n",
    "    # Calculate mean of joint distribution.\n",
    "    z_dist = np.concatenate([x_dist, y_dist])\n",
    "    z_mean = z_dist.mean()\n",
    "    \n",
    "    # Create new distributions centered on the mean of the joint distribution.\n",
    "    x_dist_adjusted = x_dist - x_mean + z_mean\n",
    "    y_dist_adjusted = y_dist - y_mean + z_mean\n",
    "    \n",
    "    bootstrapped_t_dist = np.array([\n",
    "        bootstrap_t(x_dist_adjusted, y_dist_adjusted)\n",
    "        for i in range(n_bootstraps)\n",
    "    ])\n",
    "    \n",
    "    p_value = (bootstrapped_t_dist >= t).sum() / n_bootstraps\n",
    "    \n",
    "    return (p_value, t, bootstrapped_t_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_model_dist = get_model_distances_by_build(\n",
    "    df,\n",
    "    \"simulated_sample_3\",\n",
    "    \"validation\",\n",
    "    \"normalized_fitness\"\n",
    ")\n",
    "\n",
    "example_naive_dist = get_model_distances_by_build(\n",
    "    df,\n",
    "    \"simulated_sample_3\",\n",
    "    \"validation\",\n",
    "    \"naive\"\n",
    ")\n",
    "\n",
    "example_model_difference = example_model_dist - example_naive_dist\n",
    "example_null_difference = example_model_difference - example_model_difference.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_model_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_naive_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n",
    "\n",
    "bins = np.arange(\n",
    "    min(example_model_difference.min(), example_null_difference.min()),\n",
    "    max(example_model_difference.max(), example_null_difference.max()),\n",
    "    0.5\n",
    ")\n",
    "\n",
    "ax.hist(example_model_difference, bins=bins, label=\"true fitness\", alpha=0.5)\n",
    "ax.hist(example_null_difference, bins=bins, label=\"null model\", alpha=0.5)\n",
    "\n",
    "ax.axvline(x=example_model_difference.mean(), label=\"model mean\", color=\"blue\")\n",
    "ax.axvline(x=example_null_difference.mean(), label=\"null model mean\", color=\"orange\")\n",
    "\n",
    "ax.set_xlim(-6, 6)\n",
    "\n",
    "ax.set_xlabel(\"Model - naive distance to future (AAs)\")\n",
    "ax.set_ylabel(\"Number of timepoints\")\n",
    "ax.set_title(\n",
    "    \"Example model and null distributions\\nfor differences between distances to the future\",\n",
    "    fontsize=12\n",
    ")\n",
    "\n",
    "ax.legend(frameon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all model distributions to the corresponding naive model distribution for\n",
    "# all samples and error types. Store the resulting p-values and metadata in a new\n",
    "# data frame.\n",
    "p_values = []\n",
    "bootstrapped_t_distributions = []\n",
    "\n",
    "for sample, predictors in predictors_by_sample.items():\n",
    "    sample_df = df.query(f\"sample == '{sample}'\")\n",
    "    for error_type in error_types:\n",
    "        error_type_df = sample_df.query(f\"error_type == '{error_type}'\")\n",
    "        naive_dist = error_type_df.query(\"predictors == 'naive'\")[\"validation_error\"].values\n",
    "\n",
    "        for predictor in predictors:\n",
    "            if predictor == \"naive\":\n",
    "                continue\n",
    "\n",
    "            predictor_dist = error_type_df.query(f\"predictors == '{predictor}'\")[\"validation_error\"].values\n",
    "            \n",
    "            # Calculate the difference between the model's distance to the future\n",
    "            # and the naive model's at the same timepoint. This difference should\n",
    "            # account for timepoint-to-timepoint variation observed across all models.\n",
    "            difference_dist = predictor_dist - naive_dist\n",
    "            \n",
    "            # Center the observed distribution by its mean to produce a null distribution\n",
    "            # with the same variance and a mean of zero. We want to test whether the\n",
    "            # observed differences between this model and the naive model are different\n",
    "            # from zero.\n",
    "            null_difference_dist = difference_dist - difference_dist.mean()\n",
    "            \n",
    "            # Perform the bootstrap hypothesis test between the differences distributions.\n",
    "            p_value, t, bootstrapped_t_dist = compare_distributions_by_bootstrap(\n",
    "                null_difference_dist,\n",
    "                difference_dist,\n",
    "                n_bootstraps\n",
    "            )\n",
    "            p_values.append({\n",
    "                \"sample\": sample,\n",
    "                \"error_type\": error_type,\n",
    "                \"predictors\": predictor,\n",
    "                \"t\": t,\n",
    "                \"p_value\": p_value\n",
    "            })\n",
    "            \n",
    "            bootstrapped_t_distributions.append(\n",
    "                pd.DataFrame({\n",
    "                    \"sample\": sample,\n",
    "                    \"error_type\": error_type,\n",
    "                    \"predictors\": predictor,\n",
    "                    \"empirical_t\": t,\n",
    "                    \"p_value\": p_value,\n",
    "                    \"bootstrap_t\": bootstrapped_t_dist\n",
    "                })\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrapped_t_distributions_df = pd.concat(bootstrapped_t_distributions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrapped_t_distributions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrapped_t_distributions_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empirical_t_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_df.groupby(\"predictors\")[\"p_value\"].first().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empirical_t_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_by_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = \"natural_sample_1_with_90_vpm_sliding\"\n",
    "#sample = \"simulated_sample_3\"\n",
    "error_type = \"validation\"\n",
    "error_type = \"test\"\n",
    "example_df = bootstrapped_t_distributions_df.query(f\"(sample == '{sample}') & (error_type == '{error_type}')\")\n",
    "example_df = example_df.sort_values(\"empirical_t\", ascending=False).copy()\n",
    "grouped_df = example_df.groupby(\"predictors\", sort=False)\n",
    "\n",
    "predictors = grouped_df[\"predictors\"].first().values\n",
    "empirical_t_values = grouped_df[\"empirical_t\"].first().values\n",
    "p_values = grouped_df[\"p_value\"].first().values\n",
    "\n",
    "n_rows = int(np.ceil(p_values.shape[0] / 2.0))\n",
    "n_cells = 2 * n_rows\n",
    "\n",
    "fig, all_axes = plt.subplots(\n",
    "    n_rows,\n",
    "    2,\n",
    "    figsize=(8, n_rows),\n",
    "    sharex=True,\n",
    "    sharey=True\n",
    ")\n",
    "axes = all_axes.flatten()\n",
    "bins = np.arange(-5, 5, 0.25)\n",
    "\n",
    "for i, predictor in enumerate(predictors):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    if p_values[i] < 1.0 / n_bootstraps:\n",
    "        p_value = f\"p < {1.0 / n_bootstraps}\"\n",
    "    else:\n",
    "        p_value = f\"p = {p_values[i]}\"\n",
    "    \n",
    "    ax.hist(\n",
    "        example_df.query(f\"predictors == '{predictor}'\")[\"bootstrap_t\"].values,\n",
    "        bins=bins,\n",
    "        color=histogram_color_by_predictor[predictor]\n",
    "    )\n",
    "    ax.axvline(\n",
    "        empirical_t_values[i],\n",
    "        color=\"orange\"\n",
    "    )\n",
    "    ax.text(\n",
    "        0.01,\n",
    "        0.9,\n",
    "        f\"$t$ = {empirical_t_values[i]:.2f}, {p_value}\",\n",
    "        horizontalalignment=\"left\",\n",
    "        verticalalignment=\"center\",\n",
    "        transform=ax.transAxes,\n",
    "        fontsize=10\n",
    "    )\n",
    "    \n",
    "    ax.set_title(\n",
    "        name_by_predictor[predictor].replace(\"\\n\", \" \"),\n",
    "        fontsize=10\n",
    "    )\n",
    "    \n",
    "    if i >= n_cells - 2:\n",
    "        ax.set_xlabel(\"$t$ statistic\")\n",
    "    \n",
    "fig.text(\n",
    "    0.0,\n",
    "    0.5,\n",
    "    \"bootstrap samples\",\n",
    "    rotation=\"vertical\",\n",
    "    horizontalalignment=\"center\",\n",
    "    verticalalignment=\"center\"\n",
    ")\n",
    "\n",
    "fig.text(\n",
    "    0.5,\n",
    "    0.99,\n",
    "    f\"{name_by_sample[sample]}, {error_type} period\",\n",
    "    horizontalalignment=\"center\",\n",
    "    verticalalignment=\"center\",\n",
    "    fontsize=12\n",
    ")\n",
    "\n",
    "fig.tight_layout(pad=0.75, w_pad=0.5, h_pad=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_value_df = pd.DataFrame(p_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_value_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify models whose mean distances are significantly closer to future populations than the naive model ($\\alpha=0.05$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_value_df[p_value_df[\"p_value\"] < 0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_value_df.to_csv(output_table, sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare distributions of composite and individual models\n",
    "\n",
    "Perform bootstrap hypothesis tests between composite models and their respective individual models to determine whether any composite models are significantly more accurate. We only perform these for natural populations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "composite_models = {\n",
    "    \"simulated_sample_3\": [\n",
    "        {\n",
    "            \"individual\": [\"ne_star\", \"lbi\"],\n",
    "            \"composite\": \"lbi-ne_star\"\n",
    "        },\n",
    "        {\n",
    "            \"individual\": [\"ep_x\", \"ne_star\"],\n",
    "            \"composite\": \"ep_x-ne_star\"\n",
    "        },\n",
    "        {\n",
    "            \"individual\": [\"ep_star\", \"ne_star\"],\n",
    "            \"composite\": \"ep_star-ne_star\"\n",
    "        }\n",
    "    ],\n",
    "    \"natural_sample_1_with_90_vpm_sliding\": [\n",
    "        {\n",
    "            \"individual\": [\"cTiter_x\", \"ne_star\"],\n",
    "            \"composite\": \"cTiter_x-ne_star\"\n",
    "        },\n",
    "        {\n",
    "            \"individual\": [\"ne_star\", \"lbi\"],\n",
    "            \"composite\": \"ne_star-lbi\"\n",
    "        },\n",
    "        {\n",
    "            \"individual\": [\"ep_x\", \"ne_star\"],\n",
    "            \"composite\": \"ep_x-ne_star\"\n",
    "        },\n",
    "        {\n",
    "            \"individual\": [\"ep_star\", \"ne_star\"],\n",
    "            \"composite\": \"ep_star-ne_star\"\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "composite_vs_individual_p_values = []\n",
    "\n",
    "for error_type in error_types:\n",
    "    for sample, models in composite_models.items():\n",
    "        for model in models:\n",
    "            composite_dist = get_model_distances_by_build(df, sample, error_type, model[\"composite\"])\n",
    "\n",
    "            for individual_model in model[\"individual\"]:\n",
    "                individual_dist = get_model_distances_by_build(df, sample, error_type, individual_model)\n",
    "\n",
    "                # Calculate the difference between the composite model's distance to the future\n",
    "                # and the individual model's at the same timepoint. This difference should\n",
    "                # account for timepoint-to-timepoint variation observed across all models.\n",
    "                difference_dist = composite_dist - individual_dist\n",
    "\n",
    "                # Center the observed distribution by its mean to produce a null distribution\n",
    "                # with the same variance and a mean of zero. We want to test whether the\n",
    "                # observed differences between the composite and individual models are different\n",
    "                # from zero.\n",
    "                null_difference_dist = difference_dist - difference_dist.mean()\n",
    "                \n",
    "                p_value, t, bootstrapped_t_dist = compare_distributions_by_bootstrap(\n",
    "                    null_difference_dist,\n",
    "                    difference_dist,\n",
    "                    n_bootstraps\n",
    "                )\n",
    "\n",
    "                composite_vs_individual_p_values.append({\n",
    "                    \"sample\": sample,\n",
    "                    \"error_type\": error_type,\n",
    "                    \"individual_model\": individual_model,\n",
    "                    \"composite_model\": model[\"composite\"],\n",
    "                    \"t\": t,\n",
    "                    \"p_value\": p_value\n",
    "                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "composite_vs_individual_p_values_df = pd.DataFrame(composite_vs_individual_p_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "composite_vs_individual_p_values_df.query(\"p_value < 0.05\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate bootstraps for all models and samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"error_difference\"] = df[\"validation_error\"] - df[\"null_validation_error\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_distances = []\n",
    "for (sample, error_type, predictors), group_df in df.groupby([\"sample\", \"error_type\", \"predictors\"]):\n",
    "    if sample not in predictors_by_sample:\n",
    "        continue\n",
    "        \n",
    "    if predictors not in predictors_by_sample[sample]:\n",
    "        continue\n",
    "        \n",
    "    print(f\"Processing: {sample}, {error_type}, {predictors}\")\n",
    "    \n",
    "    # Calculate difference between validation error\n",
    "    \n",
    "    bootstrap_distribution = [\n",
    "        group_df[\"error_difference\"].sample(frac=1.0, replace=True).mean()\n",
    "        for i in range(n_bootstraps)\n",
    "    ]\n",
    "    \n",
    "    bootstrap_distances.append(pd.DataFrame({\n",
    "        \"sample\": sample,\n",
    "        \"error_type\": error_type,\n",
    "        \"predictors\": predictors,\n",
    "        \"bootstrap_distance\": bootstrap_distribution\n",
    "    }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstraps_df = pd.concat(bootstrap_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstraps_df[\"model\"] = bootstraps_df[\"predictors\"].map(name_by_predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstraps_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bootstrap_distances(bootstraps_df, predictors, title, width=16, height=8):\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(width, height), gridspec_kw={\"hspace\": 0.5})\n",
    "\n",
    "    sample_name = bootstraps_df[\"sample\"].drop_duplicates().values[0]\n",
    "    bootstrap_df = bootstraps_df.query(\"error_type == 'validation'\")\n",
    "    bootstrap_df = bootstrap_df[bootstrap_df[\"predictors\"].isin(predictors)].copy()\n",
    "\n",
    "    # Use this order for both validation and test facets as in Tables 1 and 2.\n",
    "    models_order = bootstrap_df.groupby(\"model\")[\"bootstrap_distance\"].mean().sort_values().reset_index()[\"model\"].values\n",
    "    predictors_order = bootstrap_df.groupby(\"predictors\")[\"bootstrap_distance\"].mean().sort_values().reset_index()[\"predictors\"].values\n",
    "\n",
    "    median_naive_distance = bootstrap_df.query(\"predictors == 'naive'\")[\"bootstrap_distance\"].median()\n",
    "        \n",
    "    validation_ax = axes[0]\n",
    "    validation_ax = sns.violinplot(\n",
    "        x=\"model\",\n",
    "        y=\"bootstrap_distance\",\n",
    "        data=bootstrap_df,\n",
    "        order=models_order,\n",
    "        ax=validation_ax,\n",
    "        palette=color_by_model,\n",
    "        cut=0\n",
    "    )\n",
    "    \n",
    "    max_distance = bootstrap_df[\"bootstrap_distance\"].max() + 0.3\n",
    "    validation_ax.set_ylim(top=max_distance + 0.6)\n",
    "    \n",
    "    for index, predictor in enumerate(predictors_order):\n",
    "        if predictor == \"naive\":\n",
    "            continue\n",
    "            \n",
    "        p_value = p_value_df.query(f\"(sample == '{sample_name}') & (error_type == 'validation') & (predictors == '{predictor}')\")[\"p_value\"].values[0]\n",
    "        if p_value < (1.0 / n_bootstraps):\n",
    "            p_value_string = f\"p < {1.0 / n_bootstraps}\"\n",
    "        else:\n",
    "            p_value_string = f\"p = {p_value:.4f}\"\n",
    "            \n",
    "        validation_ax.text(\n",
    "            index,\n",
    "            max_distance,\n",
    "            p_value_string,\n",
    "            fontsize=12,\n",
    "            horizontalalignment=\"center\",\n",
    "            verticalalignment=\"center\"\n",
    "        )\n",
    "\n",
    "    validation_ax.axhline(y=median_naive_distance, label=\"naive\", color=\"#999999\", zorder=-10)\n",
    "    validation_ax.title.set_text(f\"Validation of {name_by_sample[sample]}\")\n",
    "\n",
    "    validation_ax.set_xlabel(\"Model\")\n",
    "    validation_ax.set_ylabel(\"Bootstrapped model - naive\\ndistance to future (AAs)\")\n",
    "\n",
    "    bootstrap_df = bootstraps_df.query(\"error_type == 'test'\")\n",
    "    bootstrap_df = bootstrap_df[bootstrap_df[\"predictors\"].isin(predictors)].copy()\n",
    "\n",
    "    median_naive_distance = bootstrap_df.query(\"predictors == 'naive'\")[\"bootstrap_distance\"].median()\n",
    "\n",
    "    test_ax = axes[1]\n",
    "    test_ax = sns.violinplot(\n",
    "        x=\"model\",\n",
    "        y=\"bootstrap_distance\",\n",
    "        data=bootstrap_df,\n",
    "        order=models_order,\n",
    "        ax=test_ax,\n",
    "        palette=color_by_model,\n",
    "        cut=0\n",
    "    )\n",
    "\n",
    "    max_distance = bootstrap_df[\"bootstrap_distance\"].max() + 0.3\n",
    "    test_ax.set_ylim(top=max_distance + 0.6)\n",
    "    \n",
    "    for index, predictor in enumerate(predictors_order):\n",
    "        if predictor == \"naive\":\n",
    "            continue\n",
    "            \n",
    "        p_value = p_value_df.query(f\"(sample == '{sample_name}') & (error_type == 'test') & (predictors == '{predictor}')\")[\"p_value\"].values[0]\n",
    "        if p_value < (1.0 / n_bootstraps):\n",
    "            p_value_string = f\"p < {1.0 / n_bootstraps}\"\n",
    "        else:\n",
    "            p_value_string = f\"p = {p_value:.4f}\"\n",
    "            \n",
    "        test_ax.text(\n",
    "            index,\n",
    "            max_distance,\n",
    "            p_value_string,\n",
    "            fontsize=12,\n",
    "            horizontalalignment=\"center\",\n",
    "            verticalalignment=\"center\"\n",
    "        )\n",
    "\n",
    "    test_ax.set_xlabel(\"Model\")\n",
    "    test_ax.set_ylabel(\"Bootstrapped model - naive\\ndistance to future (AAs)\")\n",
    "\n",
    "    test_ax.axhline(y=median_naive_distance, label=\"naive\", color=\"#999999\", zorder=-10)\n",
    "    test_ax.title.set_text(f\"Test of {name_by_sample[sample]}\")\n",
    "\n",
    "    sns.despine()\n",
    "    \n",
    "    return fig, axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = \"simulated_sample_3\"\n",
    "fig, axes = plot_bootstrap_distances(\n",
    "    bootstraps_df.query(f\"sample == '{sample}'\"),\n",
    "    predictors_by_sample[sample],\n",
    "    name_by_sample[sample],\n",
    "    width=16\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(bootstrap_figure_for_simulated_sample, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = \"natural_sample_1_with_90_vpm_sliding\"\n",
    "fig, axes = plot_bootstrap_distances(\n",
    "    bootstraps_df.query(f\"sample == '{sample}'\"),\n",
    "    predictors_by_sample[sample],\n",
    "    name_by_sample[sample],\n",
    "    width=24\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(bootstrap_figure_for_natural_sample, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
